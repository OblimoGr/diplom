{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dental-robertson",
   "metadata": {},
   "source": [
    "# Classification Experiment: Name + Description\n",
    "---\n",
    "This Notebook, includes a series of experiments, on using a node's name and description for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-template",
   "metadata": {},
   "source": [
    "Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "romantic-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import json\n",
    "import tweepy\n",
    "import time\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-cutting",
   "metadata": {},
   "source": [
    "Twitter API Authentication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "identical-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_credentials = []\n",
    "with open('../../../../twitter_credentials.json', 'r') as f:\n",
    "    twitter_credentials = json.load(f)\n",
    "\n",
    "auth = tweepy.OAuthHandler(twitter_credentials['consumer_key'], twitter_credentials['consumer_secret'])\n",
    "auth.set_access_token(twitter_credentials['access_token_key'],twitter_credentials['access_token_secret'])\n",
    "API = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-graduate",
   "metadata": {},
   "source": [
    "Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "regulated-lawsuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function For Text Normalization\n",
    "def clean_text(data):\n",
    "    urls = r'http\\S+'\n",
    "    non_unicode_char = r'\\W'\n",
    "    numbers = r'[0-9_]'\n",
    "    fix_whitespace = r'\\s+'\n",
    "    single_whitespace = ' '\n",
    "    \n",
    "    data = (data.replace([urls], single_whitespace, regex=True)\n",
    "                    .replace([non_unicode_char, numbers], single_whitespace, regex=True)\n",
    "                    .replace(fix_whitespace, single_whitespace, regex=True))\n",
    "    data = data.apply(lambda s: s.lower() if type(s) == str else s)\n",
    "    return data\n",
    "\n",
    "# Function For Support Vector Machine\n",
    "def classification_svm(X, y, vect):\n",
    "    if vect == 'TF-IDF':\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer()),\n",
    "            ('svm', svm.SVC())\n",
    "        ]\n",
    "        )\n",
    "    elif vect == 'BoW':\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', CountVectorizer()),\n",
    "            ('svm', svm.SVC())\n",
    "        ]\n",
    "        )\n",
    "\n",
    "    parameters = {'vectorizer__max_df': [0.25, 0.5, 0.75, 1],\n",
    "                  'vectorizer__min_df': [1, 5, 10, 25],\n",
    "                  'vectorizer__max_features': [10, 100, 1000, 2000, None],\n",
    "                  'svm__C' : [0.1,0.5,1,5,10],\n",
    "                  'svm__kernel':['linear', 'poly', 'rbf', 'sigmoid']\n",
    "                  }\n",
    "    \n",
    "    grid = GridSearchCV(pipeline, parameters, n_jobs = 4)\n",
    "    grid.fit(X, y)\n",
    "    \n",
    "    print(grid.best_params_)\n",
    "    return grid.best_score_\n",
    "\n",
    "# Function For Logistic Regression\n",
    "def classification_lr(X, y, vect):\n",
    "    if vect == 'TF-IDF':\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer()),\n",
    "            ('lr', LogisticRegression(max_iter=1000))\n",
    "        ]\n",
    "        )\n",
    "    elif vect == 'BoW':\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', CountVectorizer()),\n",
    "            ('lr', LogisticRegression(max_iter=1000))\n",
    "        ]\n",
    "        )\n",
    "\n",
    "    parameters = {'vectorizer__max_df': [0.25, 0.5, 0.75, 1],\n",
    "                  'vectorizer__min_df': [1, 5, 10, 25],\n",
    "                  'vectorizer__max_features': [10, 100, 1000, 2000, None],\n",
    "                  'lr__penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                  'lr__C': [0.1, 0.5, 1, 5, 10]\n",
    "                  }\n",
    "    \n",
    "    grid = GridSearchCV(pipeline, parameters, n_jobs = 4)\n",
    "    grid.fit(X, y)\n",
    "    \n",
    "    print(grid.best_params_)\n",
    "    return grid.best_score_\n",
    "\n",
    "# Function For kNN\n",
    "def classification_knn(X, y, vect):\n",
    "    if vect == 'TF-IDF':\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer()),\n",
    "            ('knn', KNeighborsClassifier())\n",
    "        ]\n",
    "        )\n",
    "    elif vect == 'BoW':\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', CountVectorizer()),\n",
    "            ('knn', KNeighborsClassifier())\n",
    "        ]\n",
    "        )\n",
    "\n",
    "    parameters = {'vectorizer__max_df': [0.25, 0.5, 0.75, 1],\n",
    "                  'vectorizer__min_df': [1, 5, 10, 25],\n",
    "                  'vectorizer__max_features': [10, 100, 1000, 2000, None],\n",
    "                  'knn__n_neighbors': [1,2,3,4,5,6,7,8,9,10],\n",
    "                  'knn__weights': ['uniform', 'distance']\n",
    "                  }\n",
    "    \n",
    "    grid = GridSearchCV(pipeline, parameters, n_jobs = 4)\n",
    "    grid.fit(X, y)\n",
    "    \n",
    "    print(grid.best_params_)\n",
    "    return grid.best_score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-times",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "---\n",
    "\n",
    "To begin with, we read our datasets, and fetch some tweets for each node creating 3 new fields:\n",
    "- recent_tweet\n",
    "- recent_10_tweets\n",
    "- recent_100_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "stopped-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Training Set\n",
    "training_set = pd.read_csv('../../../../datasets/Four-categories/four-categories-training-set.csv',\n",
    "                          usecols=['Username', 'Profile name', 'Description', 'Category'])\n",
    "training_set = training_set.replace(np.nan, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "refined-vulnerability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>Profile name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aldemar_resorts</td>\n",
       "      <td>Aldemar Resorts</td>\n",
       "      <td>Guest satisfaction is our top priority! *Luxur...</td>\n",
       "      <td>Tourism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IasonFotilas</td>\n",
       "      <td>Iasonas Fotilas</td>\n",
       "      <td>Βουλευτής ΝΔ Αχαΐας</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hellenictourism</td>\n",
       "      <td>Tourism Society</td>\n",
       "      <td>We promote the Greek Tourism Industry, we brin...</td>\n",
       "      <td>Tourism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atsipras</td>\n",
       "      <td>Αλέξης Τσίπρας - Alexis Tsipras</td>\n",
       "      <td>Πρόεδρος του ΣΥΡΙΖΑ - @syriza_gr Ι Internation...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bistro45Bexhill</td>\n",
       "      <td>Bistro 45</td>\n",
       "      <td>Family Run Bistro on The Marina in Bexhill-on-...</td>\n",
       "      <td>Foodservice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Username                     Profile name  \\\n",
       "0  aldemar_resorts                  Aldemar Resorts   \n",
       "1     IasonFotilas                  Iasonas Fotilas   \n",
       "2  hellenictourism                  Tourism Society   \n",
       "3         atsipras  Αλέξης Τσίπρας - Alexis Tsipras   \n",
       "4  Bistro45Bexhill                        Bistro 45   \n",
       "\n",
       "                                         Description     Category  \n",
       "0  Guest satisfaction is our top priority! *Luxur...      Tourism  \n",
       "1                                Βουλευτής ΝΔ Αχαΐας     Politics  \n",
       "2  We promote the Greek Tourism Industry, we brin...      Tourism  \n",
       "3  Πρόεδρος του ΣΥΡΙΖΑ - @syriza_gr Ι Internation...     Politics  \n",
       "4  Family Run Bistro on The Marina in Bexhill-on-...  Foodservice  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-bidding",
   "metadata": {},
   "source": [
    "# Case 1: name + description \n",
    "---\n",
    "In this case, we use a node's name and description  as a single feature to classify the node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-borough",
   "metadata": {},
   "source": [
    "## Text Normalization\n",
    "We start by creating a new field:\n",
    "- textdata : name + description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "meaning-retention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>Category</th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aldemar_resorts</td>\n",
       "      <td>Tourism</td>\n",
       "      <td>Aldemar Resorts Guest satisfaction is our top ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IasonFotilas</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Iasonas Fotilas Βουλευτής ΝΔ Αχαΐας</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hellenictourism</td>\n",
       "      <td>Tourism</td>\n",
       "      <td>Tourism Society We promote the Greek Tourism I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Username  Category  \\\n",
       "0  aldemar_resorts   Tourism   \n",
       "1     IasonFotilas  Politics   \n",
       "2  hellenictourism   Tourism   \n",
       "\n",
       "                                          textdata_1  \n",
       "0  Aldemar Resorts Guest satisfaction is our top ...  \n",
       "1                Iasonas Fotilas Βουλευτής ΝΔ Αχαΐας  \n",
       "2  Tourism Society We promote the Greek Tourism I...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = training_set.copy()\n",
    "data['textdata_1'] = data['Profile name'] + ' ' + data['Description']\n",
    "data = data.drop(['Profile name', 'Description'], axis = 1)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-timber",
   "metadata": {},
   "source": [
    "Next normalize our text by taking the following actions:\n",
    "\n",
    "- remove URLs\n",
    "- remove Mentions\n",
    "- remove anything that isn't a unicode character (e.g emojis, punctuation)\n",
    "- remove numbers and _\n",
    "- fix whitespace\n",
    "- convert to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cutting-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['textdata_1'] = clean_text(data['textdata_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "pediatric-lighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = {'Tourism':0, 'Foodservice':1, 'Politics':2, 'Education': 4}\n",
    "data['Category'] = data['Category'].map(codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-profile",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "casual-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_tfidf = pd.DataFrame()\n",
    "svm_bow = pd.DataFrame()\n",
    "\n",
    "lr_tfidf = pd.DataFrame()\n",
    "lr_bow = pd.DataFrame()\n",
    "\n",
    "knn_tfidf = pd.DataFrame()\n",
    "knn_bow = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-columbus",
   "metadata": {},
   "source": [
    "### Without NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "thousand-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "textdatas = ['textdata_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-physics",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "promising-aruba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089fa41bbe394c3489ce2f58012fe547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'svm__C': 1, 'svm__kernel': 'rbf', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.54333333 0.53666667 0.54       ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.9533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             textdata_1\n",
       "Without NLP      0.9533"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_svm(X, data['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_tfidf = svm_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "svm_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "becoming-router",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a17270dbd04ef5a2844cb83434c369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'svm__C': 0.5, 'svm__kernel': 'linear', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.46333333 0.47       0.47       ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.9233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             textdata_1\n",
       "Without NLP      0.9233"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_svm(X, data['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_bow = svm_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "svm_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-engagement",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "urban-album",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42505663b26240dd80d4e777d5e5e77d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'lr__C': 0.1, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             textdata_1\n",
       "Without NLP        0.96"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_lr(X, data['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_tfidf = lr_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "lr_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "supposed-virus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75eb6260d2b4bf099e8e771534efa17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'lr__C': 0.1, 'lr__penalty': 'none', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.9467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             textdata_1\n",
       "Without NLP      0.9467"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_lr(X, data['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_bow = lr_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "lr_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-bible",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "following-clothing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b1c8766fc1493b9c2387caa64cdd7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'knn__n_neighbors': 10, 'knn__weights': 'distance', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.54666667 0.54       0.53666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.9433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             textdata_1\n",
       "Without NLP      0.9433"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_knn(X, data['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_tfidf = knn_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "knn_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "listed-ukraine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd86459fb05e44df8d7033e1083ea18e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'knn__n_neighbors': 3, 'knn__weights': 'distance', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 100, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.50333333 0.5        0.5        ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.7967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             textdata_1\n",
       "Without NLP      0.7967"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_knn(X, data['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_bow = knn_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "knn_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-vegetarian",
   "metadata": {},
   "source": [
    "### Stop Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "included-plymouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_el = spacy.load('el_core_news_md')\n",
    "nlp_en = spacy.load('en_core_web_sm')\n",
    "STOPWORDS = set(list(spacy.lang.en.STOP_WORDS) + list(spacy.lang.el.STOP_WORDS))\n",
    "\n",
    "def remove_stopwords(row):\n",
    "    row = [str(token) for token in nlp_el(row)]\n",
    "    return [w for w in row if w not in STOPWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "smoking-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: remove_stopwords(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: ' '.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-kitchen",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fabulous-minority",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4cc4719875645eab6f3fe0286549071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'svm__C': 1, 'svm__kernel': 'rbf', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.54666667 0.55333333 0.54333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.9533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.9733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1\n",
       "Without NLP           0.9533\n",
       "Stopword Removal      0.9733"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_svm(X, df['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_tfidf = svm_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "svm_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "corresponding-silly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d65ed6ed0249b48cbec87e7f4990f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'svm__C': 5, 'svm__kernel': 'sigmoid', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.53333333 0.54       0.55333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.9233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.9300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1\n",
       "Without NLP           0.9233\n",
       "Stopword Removal      0.9300"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_svm(X, df['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_bow = svm_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "svm_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-knight",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "chinese-federation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163320bdbb4041c385ea1d0fefe0cdb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'lr__C': 0.5, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.9600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.9733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1\n",
       "Without NLP           0.9600\n",
       "Stopword Removal      0.9733"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_lr(X, df['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_tfidf = lr_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "lr_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "driven-skill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac9c38211c944dbfae45307275f58b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'lr__C': 0.1, 'lr__penalty': 'none', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.9467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.9567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1\n",
       "Without NLP           0.9467\n",
       "Stopword Removal      0.9567"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_lr(X, df['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_bow = lr_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "lr_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-prisoner",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "recovered-astronomy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f09a4019ae6464583294a0ba3cdb966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'knn__n_neighbors': 9, 'knn__weights': 'distance', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.45333333 0.46       0.45       ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.9433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.9667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1\n",
       "Without NLP           0.9433\n",
       "Stopword Removal      0.9667"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_knn(X, df['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_tfidf = knn_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "knn_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "saving-cleaners",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a14d69f5c48d4c55af6e3490c49d7cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'knn__n_neighbors': 4, 'knn__weights': 'distance', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 100, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.43666667 0.44333333 0.43333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.7967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.8333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1\n",
       "Without NLP           0.7967\n",
       "Stopword Removal      0.8333"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_knn(X, df['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_bow = knn_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "knn_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-taiwan",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "specific-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lemmatize(row):\n",
    "    return [str(token.lemma_) for token in nlp_el(row)]\n",
    "\n",
    "def tokenize_lemmatize_en(row):\n",
    "    return [str(token.lemma_) for token in nlp_en(row)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "circular-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: tokenize_lemmatize(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: ' '.join(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: tokenize_lemmatize_en(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: ' '.join(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: remove_stopwords(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: ' '.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-geometry",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "first-yield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a02566e2714a66bed5a9c43c337210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'svm__C': 1, 'svm__kernel': 'rbf', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.57333333 0.56666667 0.57333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.9533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.9733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.9833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1\n",
       "Without NLP           0.9533\n",
       "Stopword Removal      0.9733\n",
       "Lemmatization         0.9833"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_svm(X, df['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_tfidf = svm_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "\n",
    "svm_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cheap-links",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ab3c3c947444ffb2319ae9135a9ff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'svm__C': 1, 'svm__kernel': 'sigmoid', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.6        0.58333333 0.59333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.9233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.9300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.9433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1\n",
       "Without NLP           0.9233\n",
       "Stopword Removal      0.9300\n",
       "Lemmatization         0.9433"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bow \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_svm(X, df['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_bow = svm_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "\n",
    "svm_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-underwear",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "european-corruption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c93e1f861648d9894d7a295c934074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'lr__C': 0.1, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.9600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.9733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.9867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1\n",
       "Without NLP           0.9600\n",
       "Stopword Removal      0.9733\n",
       "Lemmatization         0.9867"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_lr(X, df['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_tfidf = lr_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "\n",
    "lr_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dressed-thing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0588498f4b4df48598fdddfe01052d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'lr__C': 0.1, 'lr__penalty': 'none', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.9467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.9567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.9633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1\n",
       "Without NLP           0.9467\n",
       "Stopword Removal      0.9567\n",
       "Lemmatization         0.9633"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_lr(X, df['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_bow = lr_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "\n",
    "lr_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-outline",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "polar-illinois",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf04827509d4cf288acc6fb805e44a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'knn__n_neighbors': 7, 'knn__weights': 'uniform', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.45333333 0.43666667 0.45       ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.9433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.9667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.9600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1\n",
       "Without NLP           0.9433\n",
       "Stopword Removal      0.9667\n",
       "Lemmatization         0.9600"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_knn(X, df['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_tfidf = knn_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "\n",
    "knn_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "large-island",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc9f3857f2b4d839c21a521a543bd11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'knn__n_neighbors': 3, 'knn__weights': 'distance', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 100, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.42666667 0.40666667 0.41666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.7967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.8333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.8467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1\n",
       "Without NLP           0.7967\n",
       "Stopword Removal      0.8333\n",
       "Lemmatization         0.8467"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_knn(X, df['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_bow = knn_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "\n",
    "knn_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-reunion",
   "metadata": {},
   "source": [
    "## Export Model\n",
    "\n",
    "\n",
    "The best model we found is: SVM-TF-IDF\n",
    "- vectorizer__max_df: 0.5\n",
    "- vectorizer__max_features: 1000\n",
    "- vectorizer__min_df: 1\n",
    "- svm__C: 1\n",
    "- svm_kernel: rbf<br>\n",
    "\n",
    "with the following NLP steps:\n",
    "- Lemmatization\n",
    "- Stop Word Removal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "defined-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_data_fourcateg_nd(df):\n",
    "    df['textdata'] = clean_text(df['Profile name'] + ' ' + df['Description'])\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: tokenize_lemmatize(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: ' '.join(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: tokenize_lemmatize_en(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: ' '.join(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: remove_stopwords(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: ' '.join(row))\n",
    "    \n",
    "    return df.textdata\n",
    "\n",
    "\n",
    "get_text = FunctionTransformer(get_text_data_fourcateg_nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "controversial-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('selector', get_text),\n",
    "    ('tfidf', TfidfVectorizer(max_df=0.25, max_features=2000, min_df=1)),\n",
    "    ('lr', LogisticRegression(penalty='l2', C=0.1, max_iter=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "addressed-central",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('selector',\n",
       "                 FunctionTransformer(func=<function get_text_data_fourcateg_nd at 0x7fef42382d30>)),\n",
       "                ('tfidf', TfidfVectorizer(max_df=0.25, max_features=2000)),\n",
       "                ('lr', LogisticRegression(C=0.1, max_iter=1000))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = training_set\n",
    "y = training_set['Category']\n",
    "pipeline.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "active-spotlight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classifier_fourcateg_nd.sav']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'classifier_fourcateg_nd.sav'\n",
    "joblib.dump(pipeline, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-lingerie",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
