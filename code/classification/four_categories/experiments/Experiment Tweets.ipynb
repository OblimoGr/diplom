{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "together-draft",
   "metadata": {},
   "source": [
    "# Classification Experiment: Tweets\n",
    "---\n",
    "This Notebook, includes a series of experiments, on using a node's tweets for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-serve",
   "metadata": {},
   "source": [
    "Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dramatic-elephant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import json\n",
    "import tweepy\n",
    "import time\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-start",
   "metadata": {},
   "source": [
    "Twitter API Authentication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sacred-thomson",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_credentials = []\n",
    "with open('../../../../twitter_credentials.json', 'r') as f:\n",
    "    twitter_credentials = json.load(f)\n",
    "\n",
    "auth = tweepy.OAuthHandler(twitter_credentials['consumer_key'], twitter_credentials['consumer_secret'])\n",
    "auth.set_access_token(twitter_credentials['access_token_key'],twitter_credentials['access_token_secret'])\n",
    "API = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, timeout=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-turner",
   "metadata": {},
   "source": [
    "Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hourly-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function For Text Normalization\n",
    "def clean_text(data):\n",
    "    urls = r'http\\S+'\n",
    "    non_unicode_char = r'\\W'\n",
    "    numbers = r'[0-9_]'\n",
    "    fix_whitespace = r'\\s+'\n",
    "    single_whitespace = ' '\n",
    "    \n",
    "    data = (data.replace([urls], single_whitespace, regex=True)\n",
    "                    .replace([non_unicode_char, numbers], single_whitespace, regex=True)\n",
    "                    .replace(fix_whitespace, single_whitespace, regex=True))\n",
    "    data = data.apply(lambda s: s.lower() if type(s) == str else s)\n",
    "    return data\n",
    "\n",
    "nlp_el = spacy.load('el_core_news_md')\n",
    "nlp_en = spacy.load('en_core_web_sm')\n",
    "STOPWORDS = set(list(spacy.lang.en.STOP_WORDS) + list(spacy.lang.el.STOP_WORDS))\n",
    "\n",
    "def remove_stopwords(row):\n",
    "    row = [str(token) for token in nlp_el(row)]\n",
    "    return [w for w in row if w not in STOPWORDS]\n",
    "\n",
    "def tokenize_lemmatize(row):\n",
    "    return [str(token.lemma_) for token in nlp_el(row)]\n",
    "\n",
    "# Function For Support Vector Machine\n",
    "def classification_svm(X, y, vect):\n",
    "    if vect == 'TF-IDF':\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer()),\n",
    "            ('svm', svm.SVC())\n",
    "        ]\n",
    "        )\n",
    "    elif vect == 'BoW':\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', CountVectorizer()),\n",
    "            ('svm', svm.SVC())\n",
    "        ]\n",
    "        )\n",
    "\n",
    "    parameters = {'vectorizer__max_df': [0.25, 0.5, 0.75, 1],\n",
    "                  'vectorizer__min_df': [1, 5, 10, 25],\n",
    "                  'vectorizer__max_features': [10, 100, 1000, 2000, None],\n",
    "                  'svm__C' : [0.1,0.5,1,5,10],\n",
    "                  'svm__kernel':['linear', 'poly', 'rbf', 'sigmoid']\n",
    "                  }\n",
    "    \n",
    "    grid = GridSearchCV(pipeline, parameters, n_jobs = 4)\n",
    "    grid.fit(X, y)\n",
    "    \n",
    "    print(grid.best_params_)\n",
    "    return grid.best_score_\n",
    "\n",
    "# Function For Logistic Regression\n",
    "def classification_lr(X, y, vect):\n",
    "    if vect == 'TF-IDF':\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer()),\n",
    "            ('lr', LogisticRegression(max_iter=1000))\n",
    "        ]\n",
    "        )\n",
    "    elif vect == 'BoW':\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', CountVectorizer()),\n",
    "            ('lr', LogisticRegression(max_iter=1000))\n",
    "        ]\n",
    "        )\n",
    "\n",
    "    parameters = {'vectorizer__max_df': [0.25, 0.5, 0.75, 1],\n",
    "                  'vectorizer__min_df': [1, 5, 10, 25],\n",
    "                  'vectorizer__max_features': [10, 100, 1000, 2000, None],\n",
    "                  'lr__penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                  'lr__C': [0.1, 0.5, 1, 5, 10]\n",
    "                  }\n",
    "    \n",
    "    grid = GridSearchCV(pipeline, parameters, n_jobs = 4)\n",
    "    grid.fit(X, y)\n",
    "    \n",
    "    print(grid.best_params_)\n",
    "    return grid.best_score_\n",
    "\n",
    "# Function For kNN\n",
    "def classification_knn(X, y, vect):\n",
    "    if vect == 'TF-IDF':\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer()),\n",
    "            ('knn', KNeighborsClassifier())\n",
    "        ]\n",
    "        )\n",
    "    elif vect == 'BoW':\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', CountVectorizer()),\n",
    "            ('knn', KNeighborsClassifier())\n",
    "        ]\n",
    "        )\n",
    "\n",
    "    parameters = {'vectorizer__max_df': [0.25, 0.5, 0.75, 1],\n",
    "                  'vectorizer__min_df': [1, 5, 10, 25],\n",
    "                  'vectorizer__max_features': [10, 100, 1000, 2000, None],\n",
    "                  'knn__n_neighbors': [1,2,3,4,5,6,7,8,9,10],\n",
    "                  'knn__weights': ['uniform', 'distance']\n",
    "                  }\n",
    "    \n",
    "    grid = GridSearchCV(pipeline, parameters, n_jobs = 4)\n",
    "    grid.fit(X, y)\n",
    "    \n",
    "    print(grid.best_params_)\n",
    "    return grid.best_score_\n",
    "\n",
    "\n",
    "def get_text_data_nd(df):\n",
    "    df['textdata'] = clean_text(df['name'] + ' ' + df['description'])\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: tokenize_lemmatize(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: ' '.join(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: remove_stopwords(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: ' '.join(row))\n",
    "    \n",
    "    return df.textdata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-tennessee",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "---\n",
    "\n",
    "To begin with, we read our datasets, and fetch some tweets for each node creating 3 new fields:\n",
    "- recent_tweet\n",
    "- recent_10_tweets\n",
    "- recent_100_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "second-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Training Set\n",
    "training_set = pd.read_csv('../../../../datasets/Four-categories/four-categories-training-set.csv')\n",
    "training_set = training_set.replace(np.nan, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "humanitarian-supervision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>Profile name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Recent Tweet</th>\n",
       "      <th>Recent 10 tweets</th>\n",
       "      <th>Recent 50 tweets</th>\n",
       "      <th>Recent 100 tweets</th>\n",
       "      <th>Tweets count</th>\n",
       "      <th>Favourites count</th>\n",
       "      <th>Followers count</th>\n",
       "      <th>Following count</th>\n",
       "      <th>Lists count</th>\n",
       "      <th>Created at</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aldemar_resorts</td>\n",
       "      <td>Aldemar Resorts</td>\n",
       "      <td>Guest satisfaction is our top priority! *Luxur...</td>\n",
       "      <td>A hotel’s operation is much more than what gue...</td>\n",
       "      <td>✨2021 Season's Greetings from all of us ✨We w...</td>\n",
       "      <td>✨2021 Season's Greetings from all of us ✨We w...</td>\n",
       "      <td>✨2021 Season's Greetings from all of us ✨We w...</td>\n",
       "      <td>1810</td>\n",
       "      <td>956</td>\n",
       "      <td>2237</td>\n",
       "      <td>1558</td>\n",
       "      <td>113</td>\n",
       "      <td>2009-07-20 08:56:13</td>\n",
       "      <td>Tourism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IasonFotilas</td>\n",
       "      <td>Iasonas Fotilas</td>\n",
       "      <td>Βουλευτής ΝΔ Αχαΐας</td>\n",
       "      <td>Τι να κάνουμε για να στηρίξουμε οικονομικά τον...</td>\n",
       "      <td>Απάντησή μου για την επίσκεψη του Προέδρου τη...</td>\n",
       "      <td>Απάντησή μου για την επίσκεψη του Προέδρου τη...</td>\n",
       "      <td>Απάντησή μου για την επίσκεψη του Προέδρου τη...</td>\n",
       "      <td>5570</td>\n",
       "      <td>3251</td>\n",
       "      <td>4667</td>\n",
       "      <td>1512</td>\n",
       "      <td>51</td>\n",
       "      <td>2015-02-26 07:45:34</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hellenictourism</td>\n",
       "      <td>Tourism Society</td>\n",
       "      <td>We promote the Greek Tourism Industry, we brin...</td>\n",
       "      <td>Ultimately, it’s not about who you know ... bu...</td>\n",
       "      <td>Ultimately, it’s not about who you know ... b...</td>\n",
       "      <td>Ultimately, it’s not about who you know ... b...</td>\n",
       "      <td>Ultimately, it’s not about who you know ... b...</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>1318</td>\n",
       "      <td>84</td>\n",
       "      <td>28</td>\n",
       "      <td>2009-10-13 07:50:27</td>\n",
       "      <td>Tourism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atsipras</td>\n",
       "      <td>Αλέξης Τσίπρας - Alexis Tsipras</td>\n",
       "      <td>Πρόεδρος του ΣΥΡΙΖΑ - @syriza_gr Ι Internation...</td>\n",
       "      <td>Η κατάσταση στη βόρεια Ελλάδα είναι δραματική....</td>\n",
       "      <td>Πιστεύω βαθιά, ότι η ειλικρίνεια και η αφοσίω...</td>\n",
       "      <td>Πιστεύω βαθιά, ότι η ειλικρίνεια και η αφοσίω...</td>\n",
       "      <td>Πιστεύω βαθιά, ότι η ειλικρίνεια και η αφοσίω...</td>\n",
       "      <td>7692</td>\n",
       "      <td>7</td>\n",
       "      <td>552743</td>\n",
       "      <td>183</td>\n",
       "      <td>1734</td>\n",
       "      <td>2011-07-13 11:08:10</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bistro45Bexhill</td>\n",
       "      <td>Bistro 45</td>\n",
       "      <td>Family Run Bistro on The Marina in Bexhill-on-...</td>\n",
       "      <td>MPs have voted for a fantasy. It’s an indictme...</td>\n",
       "      <td>MPs have voted for a fantasy. It’s an indictm...</td>\n",
       "      <td>MPs have voted for a fantasy. It’s an indictm...</td>\n",
       "      <td>MPs have voted for a fantasy. It’s an indictm...</td>\n",
       "      <td>245</td>\n",
       "      <td>35</td>\n",
       "      <td>753</td>\n",
       "      <td>1067</td>\n",
       "      <td>19</td>\n",
       "      <td>2010-11-09 16:22:45</td>\n",
       "      <td>Foodservice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Username                     Profile name  \\\n",
       "0  aldemar_resorts                  Aldemar Resorts   \n",
       "1     IasonFotilas                  Iasonas Fotilas   \n",
       "2  hellenictourism                  Tourism Society   \n",
       "3         atsipras  Αλέξης Τσίπρας - Alexis Tsipras   \n",
       "4  Bistro45Bexhill                        Bistro 45   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Guest satisfaction is our top priority! *Luxur...   \n",
       "1                                Βουλευτής ΝΔ Αχαΐας   \n",
       "2  We promote the Greek Tourism Industry, we brin...   \n",
       "3  Πρόεδρος του ΣΥΡΙΖΑ - @syriza_gr Ι Internation...   \n",
       "4  Family Run Bistro on The Marina in Bexhill-on-...   \n",
       "\n",
       "                                        Recent Tweet  \\\n",
       "0  A hotel’s operation is much more than what gue...   \n",
       "1  Τι να κάνουμε για να στηρίξουμε οικονομικά τον...   \n",
       "2  Ultimately, it’s not about who you know ... bu...   \n",
       "3  Η κατάσταση στη βόρεια Ελλάδα είναι δραματική....   \n",
       "4  MPs have voted for a fantasy. It’s an indictme...   \n",
       "\n",
       "                                    Recent 10 tweets  \\\n",
       "0   ✨2021 Season's Greetings from all of us ✨We w...   \n",
       "1   Απάντησή μου για την επίσκεψη του Προέδρου τη...   \n",
       "2   Ultimately, it’s not about who you know ... b...   \n",
       "3   Πιστεύω βαθιά, ότι η ειλικρίνεια και η αφοσίω...   \n",
       "4   MPs have voted for a fantasy. It’s an indictm...   \n",
       "\n",
       "                                    Recent 50 tweets  \\\n",
       "0   ✨2021 Season's Greetings from all of us ✨We w...   \n",
       "1   Απάντησή μου για την επίσκεψη του Προέδρου τη...   \n",
       "2   Ultimately, it’s not about who you know ... b...   \n",
       "3   Πιστεύω βαθιά, ότι η ειλικρίνεια και η αφοσίω...   \n",
       "4   MPs have voted for a fantasy. It’s an indictm...   \n",
       "\n",
       "                                   Recent 100 tweets  Tweets count  \\\n",
       "0   ✨2021 Season's Greetings from all of us ✨We w...          1810   \n",
       "1   Απάντησή μου για την επίσκεψη του Προέδρου τη...          5570   \n",
       "2   Ultimately, it’s not about who you know ... b...           140   \n",
       "3   Πιστεύω βαθιά, ότι η ειλικρίνεια και η αφοσίω...          7692   \n",
       "4   MPs have voted for a fantasy. It’s an indictm...           245   \n",
       "\n",
       "   Favourites count  Followers count  Following count  Lists count  \\\n",
       "0               956             2237             1558          113   \n",
       "1              3251             4667             1512           51   \n",
       "2                 0             1318               84           28   \n",
       "3                 7           552743              183         1734   \n",
       "4                35              753             1067           19   \n",
       "\n",
       "            Created at     Category  \n",
       "0  2009-07-20 08:56:13      Tourism  \n",
       "1  2015-02-26 07:45:34     Politics  \n",
       "2  2009-10-13 07:50:27      Tourism  \n",
       "3  2011-07-13 11:08:10     Politics  \n",
       "4  2010-11-09 16:22:45  Foodservice  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-carter",
   "metadata": {},
   "source": [
    "# Case 1: name + description + tweets\n",
    "---\n",
    "In this case, we use a node's name, description and tweets as a single feature to classify the node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-times",
   "metadata": {},
   "source": [
    "## Text Normalization\n",
    "We start by creating 3 new fields:\n",
    "- textdata_1 : name + description + recent_tweet\n",
    "- textdata_2 : name + description + recent_10_tweets\n",
    "- textdata_3 : name + description + recent_100_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "streaming-reward",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>Recent 50 tweets</th>\n",
       "      <th>Tweets count</th>\n",
       "      <th>Favourites count</th>\n",
       "      <th>Followers count</th>\n",
       "      <th>Following count</th>\n",
       "      <th>Lists count</th>\n",
       "      <th>Created at</th>\n",
       "      <th>Category</th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aldemar_resorts</td>\n",
       "      <td>✨2021 Season's Greetings from all of us ✨We w...</td>\n",
       "      <td>1810</td>\n",
       "      <td>956</td>\n",
       "      <td>2237</td>\n",
       "      <td>1558</td>\n",
       "      <td>113</td>\n",
       "      <td>2009-07-20 08:56:13</td>\n",
       "      <td>0</td>\n",
       "      <td>Aldemar Resorts Guest satisfaction is our top ...</td>\n",
       "      <td>Aldemar Resorts Guest satisfaction is our top ...</td>\n",
       "      <td>Aldemar Resorts Guest satisfaction is our top ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IasonFotilas</td>\n",
       "      <td>Απάντησή μου για την επίσκεψη του Προέδρου τη...</td>\n",
       "      <td>5570</td>\n",
       "      <td>3251</td>\n",
       "      <td>4667</td>\n",
       "      <td>1512</td>\n",
       "      <td>51</td>\n",
       "      <td>2015-02-26 07:45:34</td>\n",
       "      <td>2</td>\n",
       "      <td>Iasonas Fotilas Βουλευτής ΝΔ Αχαΐας Τι να κάνο...</td>\n",
       "      <td>Iasonas Fotilas Βουλευτής ΝΔ Αχαΐας  Απάντησή ...</td>\n",
       "      <td>Iasonas Fotilas Βουλευτής ΝΔ Αχαΐας  Απάντησή ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hellenictourism</td>\n",
       "      <td>Ultimately, it’s not about who you know ... b...</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>1318</td>\n",
       "      <td>84</td>\n",
       "      <td>28</td>\n",
       "      <td>2009-10-13 07:50:27</td>\n",
       "      <td>0</td>\n",
       "      <td>Tourism Society We promote the Greek Tourism I...</td>\n",
       "      <td>Tourism Society We promote the Greek Tourism I...</td>\n",
       "      <td>Tourism Society We promote the Greek Tourism I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Username                                   Recent 50 tweets  \\\n",
       "0  aldemar_resorts   ✨2021 Season's Greetings from all of us ✨We w...   \n",
       "1     IasonFotilas   Απάντησή μου για την επίσκεψη του Προέδρου τη...   \n",
       "2  hellenictourism   Ultimately, it’s not about who you know ... b...   \n",
       "\n",
       "   Tweets count  Favourites count  Followers count  Following count  \\\n",
       "0          1810               956             2237             1558   \n",
       "1          5570              3251             4667             1512   \n",
       "2           140                 0             1318               84   \n",
       "\n",
       "   Lists count           Created at  Category  \\\n",
       "0          113  2009-07-20 08:56:13         0   \n",
       "1           51  2015-02-26 07:45:34         2   \n",
       "2           28  2009-10-13 07:50:27         0   \n",
       "\n",
       "                                          textdata_1  \\\n",
       "0  Aldemar Resorts Guest satisfaction is our top ...   \n",
       "1  Iasonas Fotilas Βουλευτής ΝΔ Αχαΐας Τι να κάνο...   \n",
       "2  Tourism Society We promote the Greek Tourism I...   \n",
       "\n",
       "                                          textdata_2  \\\n",
       "0  Aldemar Resorts Guest satisfaction is our top ...   \n",
       "1  Iasonas Fotilas Βουλευτής ΝΔ Αχαΐας  Απάντησή ...   \n",
       "2  Tourism Society We promote the Greek Tourism I...   \n",
       "\n",
       "                                          textdata_3  \n",
       "0  Aldemar Resorts Guest satisfaction is our top ...  \n",
       "1  Iasonas Fotilas Βουλευτής ΝΔ Αχαΐας  Απάντησή ...  \n",
       "2  Tourism Society We promote the Greek Tourism I...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = training_set.copy()\n",
    "data['textdata_1'] = data['Profile name'] + ' ' + data['Description'] + ' ' + data['Recent Tweet']\n",
    "data['textdata_2'] = data['Profile name'] + ' ' + data['Description'] + ' ' + data['Recent 10 tweets']\n",
    "data['textdata_3'] = data['Profile name'] + ' ' + data['Description'] + ' ' + data['Recent 100 tweets']\n",
    "data = data.drop(['Profile name', 'Description', 'Recent Tweet', 'Recent 10 tweets', 'Recent 100 tweets'], axis = 1)\n",
    "codes = {'Tourism':0, 'Foodservice':1, 'Politics':2, 'Education': 4}\n",
    "data['Category'] = data['Category'].map(codes)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-interim",
   "metadata": {},
   "source": [
    "Next normalize our text by taking the following actions:\n",
    "\n",
    "- remove URLs\n",
    "- remove Mentions\n",
    "- remove anything that isn't a unicode character (e.g emojis, punctuation)\n",
    "- remove numbers and _\n",
    "- fix whitespace\n",
    "- convert to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "extraordinary-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['textdata_1'] = clean_text(data['textdata_1'])\n",
    "data['textdata_2'] = clean_text(data['textdata_2'])\n",
    "data['textdata_3'] = clean_text(data['textdata_3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-stick",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "intermediate-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_tfidf = pd.DataFrame()\n",
    "svm_bow = pd.DataFrame()\n",
    "\n",
    "lr_tfidf = pd.DataFrame()\n",
    "lr_bow = pd.DataFrame()\n",
    "\n",
    "knn_tfidf = pd.DataFrame()\n",
    "knn_bow = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-lexington",
   "metadata": {},
   "source": [
    "### Without NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "funky-vessel",
   "metadata": {},
   "outputs": [],
   "source": [
    "textdatas = ['textdata_1', 'textdata_2', 'textdata_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-stock",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "random-nudist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec0f506c4e54150bfdda4d073e908b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.53666667 0.53666667 0.53666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 5, 'svm__kernel': 'rbf', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.53333333 0.53333333 0.53333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 5, 'svm__kernel': 'linear', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.42666667 0.42666667 0.42666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 10, 'svm__kernel': 'linear', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 25}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.9567</td>\n",
       "      <td>0.9467</td>\n",
       "      <td>0.9533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             textdata_1  textdata_2  textdata_3\n",
       "Without NLP      0.9567      0.9467      0.9533"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_svm(X, data['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_tfidf = svm_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "svm_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "attached-testament",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5195557d83314baa98ad1b311433e575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.46666667 0.46666667 0.46666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 0.1, 'svm__kernel': 'linear', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': None, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.48333333 0.48333333 0.48333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 1, 'svm__kernel': 'sigmoid', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': None, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.41333333 0.41333333 0.41333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 10, 'svm__kernel': 'rbf', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.9267</td>\n",
       "      <td>0.9133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             textdata_1  textdata_2  textdata_3\n",
       "Without NLP      0.9167      0.9267      0.9133"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_svm(X, data['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_bow = svm_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "svm_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-process",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "basic-fishing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558dc15901bd40e1aa33708a94fa7f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 5, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.1, 'lr__penalty': 'none', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': None, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.1, 'lr__penalty': 'none', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 25}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.9667</td>\n",
       "      <td>0.9467</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             textdata_1  textdata_2  textdata_3\n",
       "Without NLP      0.9667      0.9467        0.95"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_lr(X, data['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_tfidf = lr_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "lr_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "written-survival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f46b6fcde041f7ade7c699e46127c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.1, 'lr__penalty': 'none', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.1, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': None, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.1, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': None, 'vectorizer__min_df': 5}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.9567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             textdata_1  textdata_2  textdata_3\n",
       "Without NLP        0.94      0.9333      0.9567"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_lr(X, data['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_bow = lr_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "lr_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-patient",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "selected-boxing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27dbd9957fb549b49db08f1ba3738030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.46666667 0.46666667 0.46666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 7, 'knn__weights': 'distance', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.45333333 0.45333333 0.45333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 9, 'knn__weights': 'distance', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.37 0.37 0.37 ...  nan  nan  nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 10, 'knn__weights': 'distance', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.9133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             textdata_1  textdata_2  textdata_3\n",
       "Without NLP        0.93        0.92      0.9133"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_knn(X, data['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_tfidf = knn_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "knn_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acquired-scottish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8899c003254fa7989bc79567d009f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.44333333 0.44333333 0.44333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 5, 'knn__weights': 'distance', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': 100, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.45 0.45 0.45 ...  nan  nan  nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 6, 'knn__weights': 'distance', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 100, 'vectorizer__min_df': 10}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.35333333 0.35333333 0.35333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 4, 'knn__weights': 'distance', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 100, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6433</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             textdata_1  textdata_2  textdata_3\n",
       "Without NLP      0.6667      0.6433        0.82"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_knn(X, data['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_bow = knn_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "knn_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-willow",
   "metadata": {},
   "source": [
    "### Stop Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lined-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_el = spacy.load('el_core_news_md')\n",
    "nlp_en = spacy.load('en_core_web_sm')\n",
    "STOPWORDS = set(list(spacy.lang.en.STOP_WORDS) + list(spacy.lang.el.STOP_WORDS))\n",
    "\n",
    "def remove_stopwords(row):\n",
    "    row = [str(token) for token in nlp_el(row)]\n",
    "    return [w for w in row if w not in STOPWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "anticipated-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: remove_stopwords(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: ' '.join(row))\n",
    "\n",
    "df['textdata_2'] = df['textdata_2'].apply(lambda row: remove_stopwords(row))\n",
    "df['textdata_2'] = df['textdata_2'].apply(lambda row: ' '.join(row))\n",
    "\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: remove_stopwords(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: ' '.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-delaware",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fabulous-december",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acfd2ada49f04193a2704b55447a1f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.58666667 0.58666667 0.58666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 5, 'svm__kernel': 'linear', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.55666667 0.55666667 0.55666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 0.5, 'svm__kernel': 'linear', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.52666667 0.52666667 0.52666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 1, 'svm__kernel': 'linear', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': None, 'vectorizer__min_df': 5}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.9567</td>\n",
       "      <td>0.9467</td>\n",
       "      <td>0.9533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.9733</td>\n",
       "      <td>0.9567</td>\n",
       "      <td>0.9567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1  textdata_2  textdata_3\n",
       "Without NLP           0.9567      0.9467      0.9533\n",
       "Stopword Removal      0.9733      0.9567      0.9567"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_svm(X, df['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_tfidf = svm_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "svm_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dental-cheat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6beb51fdb7f04332b667bca19c893e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.52666667 0.53       0.52666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 0.1, 'svm__kernel': 'linear', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.55333333 0.55333333 0.55333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 5, 'svm__kernel': 'sigmoid', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': None, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.53333333 0.53333333 0.53333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 0.5, 'svm__kernel': 'sigmoid', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 5}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.9267</td>\n",
       "      <td>0.9133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.9267</td>\n",
       "      <td>0.9200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1  textdata_2  textdata_3\n",
       "Without NLP           0.9167      0.9267      0.9133\n",
       "Stopword Removal      0.9333      0.9267      0.9200"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_svm(X, df['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_bow = svm_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "svm_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-expression",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "sought-uruguay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "779468279ea243b1992f462fcd4da8e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.1, 'lr__penalty': 'none', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': None, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 1, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.1, 'lr__penalty': 'none', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': None, 'vectorizer__min_df': 5}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.9667</td>\n",
       "      <td>0.9467</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.9767</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1  textdata_2  textdata_3\n",
       "Without NLP           0.9667      0.9467        0.95\n",
       "Stopword Removal      0.9767      0.9633        0.96"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_lr(X, df['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_tfidf = lr_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "lr_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "productive-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d78a7abdc7c42a29d1b40d35372f5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.1, 'lr__penalty': 'none', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.1, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': None, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.1, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 10}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.9567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.9533</td>\n",
       "      <td>0.9400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1  textdata_2  textdata_3\n",
       "Without NLP             0.94      0.9333      0.9567\n",
       "Stopword Removal        0.96      0.9533      0.9400"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_lr(X, df['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_bow = lr_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "lr_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-justice",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "boolean-worship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5be757bd7746d298a65c706d564073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.46       0.46333333 0.46       ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 7, 'knn__weights': 'distance', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.48 0.48 0.48 ...  nan  nan  nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 9, 'knn__weights': 'uniform', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.46 0.46 0.46 ...  nan  nan  nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 7, 'knn__weights': 'distance', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 5}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>0.9133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.9367</td>\n",
       "      <td>0.9400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1  textdata_2  textdata_3\n",
       "Without NLP             0.93      0.9200      0.9133\n",
       "Stopword Removal        0.96      0.9367      0.9400"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_knn(X, df['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_tfidf = knn_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "knn_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "champion-patrick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a54882921d342f2ad45df5a0062b910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.44 0.44 0.44 ...  nan  nan  nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 2, 'knn__weights': 'distance', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 100, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.44666667 0.44666667 0.44666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 1, 'knn__weights': 'uniform', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 100, 'vectorizer__min_df': 10}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.43333333 0.43333333 0.43333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 5, 'knn__weights': 'distance', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 100, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6433</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.7567</td>\n",
       "      <td>0.7100</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1  textdata_2  textdata_3\n",
       "Without NLP           0.6667      0.6433        0.82\n",
       "Stopword Removal      0.7567      0.7100        0.83"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_knn(X, df['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_bow = knn_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "knn_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-corrections",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "electoral-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lemmatize(row):\n",
    "    return [str(token.lemma_) for token in nlp_el(row)]\n",
    "\n",
    "def tokenize_lemmatize_en(row):\n",
    "    return [str(token.lemma_) for token in nlp_en(row)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "under-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: tokenize_lemmatize(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: ' '.join(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: remove_stopwords(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: ' '.join(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: tokenize_lemmatize_en(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: ' '.join(row))\n",
    "\n",
    "df['textdata_2'] = df['textdata_2'].apply(lambda row: tokenize_lemmatize(row))\n",
    "df['textdata_2'] = df['textdata_2'].apply(lambda row: ' '.join(row))\n",
    "df['textdata_2'] = df['textdata_2'].apply(lambda row: remove_stopwords(row))\n",
    "df['textdata_2'] = df['textdata_2'].apply(lambda row: ' '.join(row))\n",
    "df['textdata_2'] = df['textdata_2'].apply(lambda row: tokenize_lemmatize_en(row))\n",
    "df['textdata_2'] = df['textdata_2'].apply(lambda row: ' '.join(row))\n",
    "\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: tokenize_lemmatize(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: ' '.join(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: remove_stopwords(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: ' '.join(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: tokenize_lemmatize_en(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: ' '.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-cylinder",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "gothic-colleague",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8247edda5df642189e1bdd5234f3b16a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.62       0.61666667 0.61666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 0.5, 'svm__kernel': 'linear', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.62333333 0.62333333 0.61666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 1, 'svm__kernel': 'sigmoid', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': None, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.55666667 0.55666667 0.54666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 1, 'svm__kernel': 'sigmoid', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': None, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.9567</td>\n",
       "      <td>0.9467</td>\n",
       "      <td>0.9533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.9733</td>\n",
       "      <td>0.9567</td>\n",
       "      <td>0.9567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.9733</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1  textdata_2  textdata_3\n",
       "Without NLP           0.9567      0.9467      0.9533\n",
       "Stopword Removal      0.9733      0.9567      0.9567\n",
       "Lemmatization         0.9733      0.9633      0.9567"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_svm(X, df['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_tfidf = svm_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "\n",
    "svm_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "specified-inventory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd4cbc97dcf45b18574dec4d1d6538f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.56       0.57666667 0.57333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 1, 'svm__kernel': 'sigmoid', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.59666667 0.59666667 0.61       ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 5, 'svm__kernel': 'sigmoid', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': None, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.57       0.57       0.53333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 0.5, 'svm__kernel': 'sigmoid', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 5}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.9267</td>\n",
       "      <td>0.9133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.9267</td>\n",
       "      <td>0.9200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.9433</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.9267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1  textdata_2  textdata_3\n",
       "Without NLP           0.9167      0.9267      0.9133\n",
       "Stopword Removal      0.9333      0.9267      0.9200\n",
       "Lemmatization         0.9433      0.9333      0.9267"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_svm(X, df['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_bow = svm_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "\n",
    "svm_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-solomon",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "confused-surgeon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ff320483654fb88e97b3abe119c275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 1, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.1, 'lr__penalty': 'none', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 5}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.1, 'lr__penalty': 'none', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 5}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.9667</td>\n",
       "      <td>0.9467</td>\n",
       "      <td>0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.9767</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.9733</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1  textdata_2  textdata_3\n",
       "Without NLP           0.9667      0.9467      0.9500\n",
       "Stopword Removal      0.9767      0.9633      0.9600\n",
       "Lemmatization         0.9733      0.9633      0.9633"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_lr(X, df['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_tfidf = lr_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "\n",
    "lr_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "realistic-compensation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "886a118742b947a2b789bf6bce095e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.1, 'lr__penalty': 'none', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.1, 'lr__penalty': 'none', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': None, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.1, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 10}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.9567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.9533</td>\n",
       "      <td>0.9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9433</td>\n",
       "      <td>0.9500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1  textdata_2  textdata_3\n",
       "Without NLP           0.9400      0.9333      0.9567\n",
       "Stopword Removal      0.9600      0.9533      0.9400\n",
       "Lemmatization         0.9633      0.9433      0.9500"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_lr(X, df['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_bow = lr_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "\n",
    "lr_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-berlin",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "sensitive-container",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915d7d49e41040e0b9046e04e4aa2d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.56       0.56333333 0.56       ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 10, 'knn__weights': 'distance', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': None, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.53666667 0.53666667 0.55       ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 10, 'knn__weights': 'uniform', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.46333333 0.46333333 0.45333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 10, 'knn__weights': 'distance', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 5}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>0.9133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.9367</td>\n",
       "      <td>0.9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.9367</td>\n",
       "      <td>0.9367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1  textdata_2  textdata_3\n",
       "Without NLP             0.93      0.9200      0.9133\n",
       "Stopword Removal        0.96      0.9367      0.9400\n",
       "Lemmatization           0.96      0.9367      0.9367"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_knn(X, df['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_tfidf = knn_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "\n",
    "knn_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "physical-paris",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708000a79e33474896559925c24027d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.52666667 0.54666667 0.53       ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 3, 'knn__weights': 'distance', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 100, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.51666667 0.51666667 0.52       ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 3, 'knn__weights': 'distance', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 100, 'vectorizer__min_df': 5}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.45333333 0.45333333 0.44       ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 4, 'knn__weights': 'distance', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 100, 'vectorizer__min_df': 25}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6433</td>\n",
       "      <td>0.8200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.7567</td>\n",
       "      <td>0.7100</td>\n",
       "      <td>0.8300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.7667</td>\n",
       "      <td>0.7100</td>\n",
       "      <td>0.8367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1  textdata_2  textdata_3\n",
       "Without NLP           0.6667      0.6433      0.8200\n",
       "Stopword Removal      0.7567      0.7100      0.8300\n",
       "Lemmatization         0.7667      0.7100      0.8367"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_knn(X, df['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_bow = knn_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "knn_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-dressing",
   "metadata": {},
   "source": [
    "### Export Model\n",
    "- TF-IDF outperformed BoW with in every case.\n",
    "- Highest Accuracy was achieved using recent 100 tweets\n",
    "- Support Vector Machine and Logistic Regression have a better performance.\n",
    "- Logistic Regression Reached the highest achieved accuracy with less NLP steps than Support Vector Machines\n",
    "\n",
    "The best models we found are: Logistic Regression-TF-IDF and Support Vector Machines - TF-IDF.\n",
    "We chose logistic regression as is required less preprocessing steps.\n",
    "\n",
    "- vectorizer__max_df: 0.75\n",
    "- vectorizer__max_features: None\n",
    "- vectorizer__min_df: 1\n",
    "- lr__penalty: None<br>\n",
    "\n",
    "with the following NLP steps:\n",
    "- Lemmatization\n",
    "- Stop Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "speaking-taste",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_data_ndt(df):\n",
    "    df['textdata'] = clean_text(df['Profile name'] + ' ' + df['Description'] + ' ' + df['Recent 100 tweets'])\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: tokenize_lemmatize(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: ' '.join(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: tokenize_lemmatize_en(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: ' '.join(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: remove_stopwords(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: ' '.join(row))\n",
    "    return df.textdata\n",
    "\n",
    "\n",
    "get_text_ndt = FunctionTransformer(get_text_data_ndt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mathematical-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('selector_ndt', get_text_ndt),\n",
    "    ('tfidf', TfidfVectorizer(max_df=0.75, max_features=2000, min_df=5)),\n",
    "    ('lr', LogisticRegression(max_iter=1000, penalty = 'none'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baking-meditation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('selector_ndt',\n",
       "                 FunctionTransformer(func=<function get_text_data_ndt at 0x7f82f73eeca0>)),\n",
       "                ('tfidf',\n",
       "                 TfidfVectorizer(max_df=0.75, max_features=2000, min_df=5)),\n",
       "                ('lr', LogisticRegression(max_iter=1000, penalty='none'))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = training_set\n",
    "y = training_set.Category\n",
    "pipeline.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rubber-continent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../classifiers/classifier_fourcateg_ndt.sav']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '../classifiers/classifier_fourcateg_ndt.sav'\n",
    "joblib.dump(pipeline, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-championship",
   "metadata": {},
   "source": [
    "# Case 2: Tweets Only\n",
    "---\n",
    "In this case we fetch 100 tweets if possible for each node, and try to classify them using only their tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-thirty",
   "metadata": {},
   "source": [
    "## Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "southwest-mining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>Recent 50 tweets</th>\n",
       "      <th>Tweets count</th>\n",
       "      <th>Favourites count</th>\n",
       "      <th>Followers count</th>\n",
       "      <th>Following count</th>\n",
       "      <th>Lists count</th>\n",
       "      <th>Created at</th>\n",
       "      <th>Category</th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aldemar_resorts</td>\n",
       "      <td>✨2021 Season's Greetings from all of us ✨We w...</td>\n",
       "      <td>1810</td>\n",
       "      <td>956</td>\n",
       "      <td>2237</td>\n",
       "      <td>1558</td>\n",
       "      <td>113</td>\n",
       "      <td>2009-07-20 08:56:13</td>\n",
       "      <td>0</td>\n",
       "      <td>A hotel’s operation is much more than what gue...</td>\n",
       "      <td>✨2021 Season's Greetings from all of us ✨We w...</td>\n",
       "      <td>✨2021 Season's Greetings from all of us ✨We w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IasonFotilas</td>\n",
       "      <td>Απάντησή μου για την επίσκεψη του Προέδρου τη...</td>\n",
       "      <td>5570</td>\n",
       "      <td>3251</td>\n",
       "      <td>4667</td>\n",
       "      <td>1512</td>\n",
       "      <td>51</td>\n",
       "      <td>2015-02-26 07:45:34</td>\n",
       "      <td>2</td>\n",
       "      <td>Τι να κάνουμε για να στηρίξουμε οικονομικά τον...</td>\n",
       "      <td>Απάντησή μου για την επίσκεψη του Προέδρου τη...</td>\n",
       "      <td>Απάντησή μου για την επίσκεψη του Προέδρου τη...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hellenictourism</td>\n",
       "      <td>Ultimately, it’s not about who you know ... b...</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>1318</td>\n",
       "      <td>84</td>\n",
       "      <td>28</td>\n",
       "      <td>2009-10-13 07:50:27</td>\n",
       "      <td>0</td>\n",
       "      <td>Ultimately, it’s not about who you know ... bu...</td>\n",
       "      <td>Ultimately, it’s not about who you know ... b...</td>\n",
       "      <td>Ultimately, it’s not about who you know ... b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Username                                   Recent 50 tweets  \\\n",
       "0  aldemar_resorts   ✨2021 Season's Greetings from all of us ✨We w...   \n",
       "1     IasonFotilas   Απάντησή μου για την επίσκεψη του Προέδρου τη...   \n",
       "2  hellenictourism   Ultimately, it’s not about who you know ... b...   \n",
       "\n",
       "   Tweets count  Favourites count  Followers count  Following count  \\\n",
       "0          1810               956             2237             1558   \n",
       "1          5570              3251             4667             1512   \n",
       "2           140                 0             1318               84   \n",
       "\n",
       "   Lists count           Created at  Category  \\\n",
       "0          113  2009-07-20 08:56:13         0   \n",
       "1           51  2015-02-26 07:45:34         2   \n",
       "2           28  2009-10-13 07:50:27         0   \n",
       "\n",
       "                                          textdata_1  \\\n",
       "0  A hotel’s operation is much more than what gue...   \n",
       "1  Τι να κάνουμε για να στηρίξουμε οικονομικά τον...   \n",
       "2  Ultimately, it’s not about who you know ... bu...   \n",
       "\n",
       "                                          textdata_2  \\\n",
       "0   ✨2021 Season's Greetings from all of us ✨We w...   \n",
       "1   Απάντησή μου για την επίσκεψη του Προέδρου τη...   \n",
       "2   Ultimately, it’s not about who you know ... b...   \n",
       "\n",
       "                                          textdata_3  \n",
       "0   ✨2021 Season's Greetings from all of us ✨We w...  \n",
       "1   Απάντησή μου για την επίσκεψη του Προέδρου τη...  \n",
       "2   Ultimately, it’s not about who you know ... b...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = training_set.copy()\n",
    "data['textdata_1'] = data['Recent Tweet']\n",
    "data['textdata_2'] = data['Recent 10 tweets']\n",
    "data['textdata_3'] = data['Recent 100 tweets']\n",
    "data = data.drop(['Profile name', 'Description', 'Recent Tweet', 'Recent 10 tweets', 'Recent 100 tweets'], axis = 1)\n",
    "codes = {'Tourism':0, 'Foodservice':1, 'Politics':2, 'Education': 4}\n",
    "data['Category'] = data['Category'].map(codes)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-python",
   "metadata": {},
   "source": [
    "We normalize our text by taking the following actions:\n",
    "\n",
    "- remove URLs\n",
    "- remove anything that isn't a unicode character (e.g emojis, punctuation)\n",
    "- remove numbers and _\n",
    "- fix whitespace\n",
    "- convert to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "restricted-format",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['textdata_1'] = clean_text(data['textdata_1'])\n",
    "data['textdata_2'] = clean_text(data['textdata_2'])\n",
    "data['textdata_3'] = clean_text(data['textdata_3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-server",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "affected-future",
   "metadata": {},
   "outputs": [],
   "source": [
    "textdatas = ['textdata_1', 'textdata_2', 'textdata_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "mental-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_tfidf = pd.DataFrame()\n",
    "svm_bow = pd.DataFrame()\n",
    "\n",
    "lr_tfidf = pd.DataFrame()\n",
    "lr_bow = pd.DataFrame()\n",
    "\n",
    "knn_tfidf = pd.DataFrame()\n",
    "knn_bow = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-reviewer",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "enormous-envelope",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a47a63e484649a590edeecd192f8335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.34       0.34666667 0.34666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 1, 'svm__kernel': 'poly', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.37333333 0.37333333 0.37333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 1, 'svm__kernel': 'sigmoid', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.42333333 0.42333333 0.42333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 10, 'svm__kernel': 'sigmoid', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 5}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.8833</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             textdata_1  textdata_2  textdata_3\n",
       "Without NLP        0.53      0.8833        0.93"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_svm(X, data['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_tfidf = svm_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "svm_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dressed-humanitarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a269d58a23704d0ab6d83a27ed5b0e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.35666667 0.35       0.35       ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 5, 'svm__kernel': 'sigmoid', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.37333333 0.39333333 0.37666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 1, 'svm__kernel': 'sigmoid', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.41333333 0.41333333 0.41333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 0.1, 'svm__kernel': 'linear', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': None, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.4833</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             textdata_1  textdata_2  textdata_3\n",
       "Without NLP      0.4833      0.8333        0.91"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_svm(X, data['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_bow = svm_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "svm_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-motor",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "excellent-franchise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253afa24335148b794ba1a11312aba34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 5, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 1, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.1, 'lr__penalty': 'none', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 5}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             textdata_1  textdata_2  textdata_3\n",
       "Without NLP      0.5333        0.88        0.93"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_lr(X, data['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_tfidf = lr_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "lr_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "surrounded-string",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61382faad74f4fa4bd16048dabee1e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 1, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.1, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.1, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 5}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.5033</td>\n",
       "      <td>0.8467</td>\n",
       "      <td>0.9533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             textdata_1  textdata_2  textdata_3\n",
       "Without NLP      0.5033      0.8467      0.9533"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_lr(X, data['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_bow = lr_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "lr_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-madness",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "alpha-great",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a799db72584a6e92736bfc7b0c7cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.28 0.29 0.29 ...  nan  nan  nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 9, 'knn__weights': 'distance', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.30666667 0.34333333 0.30333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 10, 'knn__weights': 'uniform', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.37 0.37 0.37 ...  nan  nan  nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 9, 'knn__weights': 'distance', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 5}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.4633</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             textdata_1  textdata_2  textdata_3\n",
       "Without NLP      0.4633        0.74        0.89"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_knn(X, data['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_tfidf = knn_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "knn_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "exotic-appointment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b707397e9cb342dfb09b928affb381f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.29666667 0.30333333 0.30333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 7, 'knn__weights': 'uniform', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 10, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.36333333 0.37666667 0.34666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 10, 'knn__weights': 'distance', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 5}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.36333333 0.36333333 0.36333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 4, 'knn__weights': 'distance', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 100, 'vectorizer__min_df': 25}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.3933</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.8133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             textdata_1  textdata_2  textdata_3\n",
       "Without NLP      0.3933        0.52      0.8133"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_knn(X, data['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_bow = knn_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "knn_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-canberra",
   "metadata": {},
   "source": [
    "### Stop Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "timely-combat",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_el = spacy.load('el_core_news_md')\n",
    "nlp_en = spacy.load('en_core_web_sm')\n",
    "STOPWORDS = set(list(spacy.lang.en.STOP_WORDS) + list(spacy.lang.el.STOP_WORDS))\n",
    "\n",
    "def remove_stopwords(row):\n",
    "    row = [str(token) for token in nlp_el(row)]\n",
    "    return [w for w in row if w not in STOPWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "existing-triangle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: remove_stopwords(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: ' '.join(row))\n",
    "\n",
    "df['textdata_2'] = df['textdata_2'].apply(lambda row: remove_stopwords(row))\n",
    "df['textdata_2'] = df['textdata_2'].apply(lambda row: ' '.join(row))\n",
    "\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: remove_stopwords(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: ' '.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-shade",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "forty-payday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06886551199e4c448de40e727c283f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.34333333 0.35       0.35       ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 1, 'svm__kernel': 'rbf', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.39 0.39 0.39 ...  nan  nan  nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 0.5, 'svm__kernel': 'linear', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.52333333 0.52333333 0.52333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 1, 'svm__kernel': 'linear', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': None, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.8833</td>\n",
       "      <td>0.9300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.5233</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>0.9467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1  textdata_2  textdata_3\n",
       "Without NLP           0.5300      0.8833      0.9300\n",
       "Stopword Removal      0.5233      0.8900      0.9467"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_svm(X, df['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_tfidf = svm_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "svm_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "utility-cyprus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c137f7a88e41ada89a53b2998be520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.32666667 0.32666667 0.33       ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 0.5, 'svm__kernel': 'linear', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.38666667 0.38666667 0.38666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 1, 'svm__kernel': 'sigmoid', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': None, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.54 0.54 0.54 ...  nan  nan  nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 0.5, 'svm__kernel': 'sigmoid', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 5}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.4833</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.9100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.9167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1  textdata_2  textdata_3\n",
       "Without NLP           0.4833      0.8333      0.9100\n",
       "Stopword Removal      0.4767      0.8600      0.9167"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_svm(X, df['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_bow = svm_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "svm_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-venice",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "encouraging-phenomenon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed3374dae3cf4d6fa0915ca79e256d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.1, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 10, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': None, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 5, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 5}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.9300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.9467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1  textdata_2  textdata_3\n",
       "Without NLP           0.5333        0.88      0.9300\n",
       "Stopword Removal      0.5300        0.89      0.9467"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_lr(X, df['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_tfidf = lr_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "lr_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "metropolitan-gauge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2937b7fc680f464f82279a7384c25695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 5, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.1, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': None, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.1, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 5}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.5033</td>\n",
       "      <td>0.8467</td>\n",
       "      <td>0.9533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.9367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1  textdata_2  textdata_3\n",
       "Without NLP           0.5033      0.8467      0.9533\n",
       "Stopword Removal      0.5000      0.8600      0.9367"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_lr(X, df['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_bow = lr_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "lr_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-seventh",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "perceived-leeds",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5460d798b7d4d93b4d9c85d540b7b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.32666667 0.33333333 0.29666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 8, 'knn__weights': 'uniform', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.35 0.35 0.35 ...  nan  nan  nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 10, 'knn__weights': 'uniform', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.43666667 0.43666667 0.43666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 9, 'knn__weights': 'uniform', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': None, 'vectorizer__min_df': 5}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.4633</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.8900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.4633</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.9233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1  textdata_2  textdata_3\n",
       "Without NLP           0.4633        0.74      0.8900\n",
       "Stopword Removal      0.4633        0.76      0.9233"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_knn(X, df['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_tfidf = knn_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "knn_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "communist-sheep",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5109738fa936434b8d0a0e9b7aca2d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.32666667 0.33333333 0.30333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 1, 'knn__weights': 'uniform', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 100, 'vectorizer__min_df': 5}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.34333333 0.34333333 0.34333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 3, 'knn__weights': 'distance', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 100, 'vectorizer__min_df': 10}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.42333333 0.42333333 0.42333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 7, 'knn__weights': 'distance', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 100, 'vectorizer__min_df': 5}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.3933</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.8133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.8200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1  textdata_2  textdata_3\n",
       "Without NLP           0.3933        0.52      0.8133\n",
       "Stopword Removal      0.3500        0.52      0.8200"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_knn(X, df['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_bow = knn_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "knn_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-testing",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "sudden-scout",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lemmatize(row):\n",
    "    return [str(token.lemma_) for token in nlp_el(row)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "recorded-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: tokenize_lemmatize(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: ' '.join(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: remove_stopwords(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: ' '.join(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: tokenize_lemmatize_en(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: ' '.join(row))\n",
    "\n",
    "df['textdata_2'] = df['textdata_2'].apply(lambda row: tokenize_lemmatize(row))\n",
    "df['textdata_2'] = df['textdata_2'].apply(lambda row: ' '.join(row))\n",
    "df['textdata_2'] = df['textdata_2'].apply(lambda row: remove_stopwords(row))\n",
    "df['textdata_2'] = df['textdata_2'].apply(lambda row: ' '.join(row))\n",
    "df['textdata_2'] = df['textdata_2'].apply(lambda row: tokenize_lemmatize_en(row))\n",
    "df['textdata_2'] = df['textdata_2'].apply(lambda row: ' '.join(row))\n",
    "\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: tokenize_lemmatize(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: ' '.join(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: remove_stopwords(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: ' '.join(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: tokenize_lemmatize_en(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: ' '.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-leadership",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "recreational-exploration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ec42f1813d43e88e2a9c965a4ca288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.36333333 0.35666667 0.34666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 1, 'svm__kernel': 'sigmoid', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.49666667 0.49666667 0.49333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 1, 'svm__kernel': 'sigmoid', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.54666667 0.54666667 0.55       ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 0.5, 'svm__kernel': 'sigmoid', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': None, 'vectorizer__min_df': 5}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.8833</td>\n",
       "      <td>0.9300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.5233</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>0.9467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.5767</td>\n",
       "      <td>0.8967</td>\n",
       "      <td>0.9467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1  textdata_2  textdata_3\n",
       "Without NLP           0.5300      0.8833      0.9300\n",
       "Stopword Removal      0.5233      0.8900      0.9467\n",
       "Lemmatization         0.5767      0.8967      0.9467"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_svm(X, df['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_tfidf = svm_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "\n",
    "svm_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "otherwise-ethernet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae08b58b78b84432b0582a20889cc35e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.29       0.29       0.32666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 1, 'svm__kernel': 'sigmoid', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.52666667 0.52666667 0.51666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 1, 'svm__kernel': 'sigmoid', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': None, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.53333333 0.53333333 0.53333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 0.1, 'svm__kernel': 'linear', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': None, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.4833</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.9100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.9167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.5067</td>\n",
       "      <td>0.8700</td>\n",
       "      <td>0.9200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1  textdata_2  textdata_3\n",
       "Without NLP           0.4833      0.8333      0.9100\n",
       "Stopword Removal      0.4767      0.8600      0.9167\n",
       "Lemmatization         0.5067      0.8700      0.9200"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_svm(X, df['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_bow = svm_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "\n",
    "svm_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-kingdom",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "municipal-orlando",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817cff7e813f4292baa77c501dcc7cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.5, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 1, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 1, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 5}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.9300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>0.9467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.5867</td>\n",
       "      <td>0.8933</td>\n",
       "      <td>0.9500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1  textdata_2  textdata_3\n",
       "Without NLP           0.5333      0.8800      0.9300\n",
       "Stopword Removal      0.5300      0.8900      0.9467\n",
       "Lemmatization         0.5867      0.8933      0.9500"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_lr(X, df['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_tfidf = lr_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "\n",
    "lr_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "chemical-weekend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae7ecccf7ca4777924b679bac73e0e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 5, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.5, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': None, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.1, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': None, 'vectorizer__min_df': 5}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.5033</td>\n",
       "      <td>0.8467</td>\n",
       "      <td>0.9533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.9367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.5467</td>\n",
       "      <td>0.8833</td>\n",
       "      <td>0.9467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1  textdata_2  textdata_3\n",
       "Without NLP           0.5033      0.8467      0.9533\n",
       "Stopword Removal      0.5000      0.8600      0.9367\n",
       "Lemmatization         0.5467      0.8833      0.9467"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_lr(X, df['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_bow = lr_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "\n",
    "lr_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-saturday",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "provincial-spirituality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8241ed64e91f404e9a716949cb184d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.31       0.31333333 0.29       ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 10, 'knn__weights': 'uniform', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.44333333 0.44333333 0.43333333 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 10, 'knn__weights': 'distance', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.45       0.45       0.45666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 9, 'knn__weights': 'uniform', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 5}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.4633</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.8900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.4633</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.9233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.9167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1  textdata_2  textdata_3\n",
       "Without NLP           0.4633        0.74      0.8900\n",
       "Stopword Removal      0.4633        0.76      0.9233\n",
       "Lemmatization         0.4900        0.78      0.9167"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_knn(X, df['Category'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_tfidf = knn_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "\n",
    "knn_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "periodic-robertson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af0acbc423a4591bac36914caf2aec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.33       0.32333333 0.29666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 10, 'knn__weights': 'distance', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 100, 'vectorizer__min_df': 1}\n",
      "============================\n",
      "Best params for textdata_2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.41666667 0.41666667 0.42       ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 4, 'knn__weights': 'distance', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 100, 'vectorizer__min_df': 5}\n",
      "============================\n",
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.43666667 0.43666667 0.43666667 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 5, 'knn__weights': 'uniform', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 100, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "      <th>textdata_2</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.3933</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.8133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.8200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.5533</td>\n",
       "      <td>0.8333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1  textdata_2  textdata_3\n",
       "Without NLP           0.3933      0.5200      0.8133\n",
       "Stopword Removal      0.3500      0.5200      0.8200\n",
       "Lemmatization         0.3500      0.5533      0.8333"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_knn(X, df['Category'], 'BoW').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_bow = knn_bow.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "knn_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-maker",
   "metadata": {},
   "source": [
    "### Export Model\n",
    "- TF-IDF outperformed BoW with in every case except with Logistic Regression, where they had similar performances\n",
    "- Logistic Regression had the best performance, and kNN the worst\n",
    "\n",
    "The best model we found is: Logistic Regression-TF-IDF\n",
    "- vectorizer__max_df: 0.75\n",
    "- vectorizer__max_features: None\n",
    "- vectorizer__min_df: 5\n",
    "- lr__C: 0.1\n",
    "- lr__penalty: none<br>\n",
    "\n",
    "with the following NLP steps:\n",
    "- Stop Word Removal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "primary-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_data_t(df):\n",
    "    df['textdata'] = clean_text(df['Recent 100 tweets'])\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: tokenize_lemmatize(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: ' '.join(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: tokenize_lemmatize_en(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: ' '.join(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: remove_stopwords(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: ' '.join(row))\n",
    "    return df.textdata\n",
    "\n",
    "\n",
    "get_text_t = FunctionTransformer(get_text_data_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aerial-persian",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('selector_t', get_text_t),\n",
    "    ('tfidf', TfidfVectorizer(max_df=0.75, max_features=2000, min_df=5)),\n",
    "    ('lr', LogisticRegression(max_iter=1000, penalty = 'l2', C=1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "focused-bleeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('selector_t',\n",
       "                 FunctionTransformer(func=<function get_text_data_t at 0x7f82f71ace50>)),\n",
       "                ('tfidf',\n",
       "                 TfidfVectorizer(max_df=0.75, max_features=2000, min_df=5)),\n",
       "                ('lr', LogisticRegression(C=1, max_iter=1000))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = training_set\n",
    "y = training_set.Category\n",
    "pipeline.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "objective-operation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../classifiers/classifier_fourcateg_t.sav']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '../classifiers/classifier_fourcateg_t.sav'\n",
    "joblib.dump(pipeline, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-narrative",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
