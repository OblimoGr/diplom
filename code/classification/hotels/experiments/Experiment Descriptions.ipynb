{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "optical-commissioner",
   "metadata": {},
   "source": [
    "# Classification Experiment: Name + Description\n",
    "---\n",
    "This Notebook, includes a series of experiments, on using a node's name and description for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-arbitration",
   "metadata": {},
   "source": [
    "Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "confidential-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import json\n",
    "import tweepy\n",
    "import time\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-hundred",
   "metadata": {},
   "source": [
    "Twitter API Authentication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "meaning-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_credentials = []\n",
    "with open('../../../../twitter_credentials.json', 'r') as f:\n",
    "    twitter_credentials = json.load(f)\n",
    "\n",
    "auth = tweepy.OAuthHandler(twitter_credentials['consumer_key'], twitter_credentials['consumer_secret'])\n",
    "auth.set_access_token(twitter_credentials['access_token_key'],twitter_credentials['access_token_secret'])\n",
    "API = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-citizen",
   "metadata": {},
   "source": [
    "Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "chubby-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function For Text Normalization\n",
    "def clean_text(data):\n",
    "    urls = r'http\\S+'\n",
    "    non_unicode_char = r'\\W'\n",
    "    numbers = r'[0-9_]'\n",
    "    fix_whitespace = r'\\s+'\n",
    "    single_whitespace = ' '\n",
    "    \n",
    "    data = (data.replace([urls], single_whitespace, regex=True)\n",
    "                    .replace([non_unicode_char, numbers], single_whitespace, regex=True)\n",
    "                    .replace(fix_whitespace, single_whitespace, regex=True))\n",
    "    data = data.apply(lambda s: s.lower() if type(s) == str else s)\n",
    "    return data\n",
    "\n",
    "# Function For Support Vector Machine\n",
    "def classification_svm(X, y, vect):\n",
    "    if vect == 'TF-IDF':\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer()),\n",
    "            ('svm', svm.SVC())\n",
    "        ]\n",
    "        )\n",
    "    elif vect == 'BoW':\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', CountVectorizer()),\n",
    "            ('svm', svm.SVC())\n",
    "        ]\n",
    "        )\n",
    "\n",
    "    parameters = {'vectorizer__max_df': [0.25, 0.5, 0.75, 1],\n",
    "                  'vectorizer__min_df': [1, 5, 10, 25],\n",
    "                  'vectorizer__max_features': [10, 100, 1000, 2000, None],\n",
    "                  'svm__C' : [0.1,0.5,1,5,10],\n",
    "                  'svm__kernel':['linear', 'poly', 'rbf', 'sigmoid']\n",
    "                  }\n",
    "    \n",
    "    grid = GridSearchCV(pipeline, parameters, n_jobs = 4)\n",
    "    grid.fit(X, y)\n",
    "    \n",
    "    print(grid.best_params_)\n",
    "    return grid.best_score_\n",
    "\n",
    "# Function For Logistic Regression\n",
    "def classification_lr(X, y, vect):\n",
    "    if vect == 'TF-IDF':\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer()),\n",
    "            ('lr', LogisticRegression(max_iter=1000))\n",
    "        ]\n",
    "        )\n",
    "    elif vect == 'BoW':\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', CountVectorizer()),\n",
    "            ('lr', LogisticRegression(max_iter=1000))\n",
    "        ]\n",
    "        )\n",
    "\n",
    "    parameters = {'vectorizer__max_df': [0.25, 0.5, 0.75, 1],\n",
    "                  'vectorizer__min_df': [1, 5, 10, 25],\n",
    "                  'vectorizer__max_features': [10, 100, 1000, 2000, None],\n",
    "                  'lr__penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                  'lr__C': [0.1, 0.5, 1, 5, 10]\n",
    "                  }\n",
    "    \n",
    "    grid = GridSearchCV(pipeline, parameters, n_jobs = 4)\n",
    "    grid.fit(X, y)\n",
    "    \n",
    "    print(grid.best_params_)\n",
    "    return grid.best_score_\n",
    "\n",
    "# Function For kNN\n",
    "def classification_knn(X, y, vect):\n",
    "    if vect == 'TF-IDF':\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer()),\n",
    "            ('knn', KNeighborsClassifier())\n",
    "        ]\n",
    "        )\n",
    "    elif vect == 'BoW':\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', CountVectorizer()),\n",
    "            ('knn', KNeighborsClassifier())\n",
    "        ]\n",
    "        )\n",
    "\n",
    "    parameters = {'vectorizer__max_df': [0.25, 0.5, 0.75, 1],\n",
    "                  'vectorizer__min_df': [1, 5, 10, 25],\n",
    "                  'vectorizer__max_features': [10, 100, 1000, 2000, None],\n",
    "                  'knn__n_neighbors': [1,2,3,4,5,6,7,8,9,10],\n",
    "                  'knn__weights': ['uniform', 'distance']\n",
    "                  }\n",
    "    \n",
    "    grid = GridSearchCV(pipeline, parameters, n_jobs = 4)\n",
    "    grid.fit(X, y)\n",
    "    \n",
    "    print(grid.best_params_)\n",
    "    return grid.best_score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-motivation",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "---\n",
    "\n",
    "To begin with, we read our datasets, and fetch some tweets for each node creating 3 new fields:\n",
    "- recent_tweet\n",
    "- recent_10_tweets\n",
    "- recent_100_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "broad-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Training Set\n",
    "training_set = pd.read_csv('../../../../datasets/Hotels/classification/hotels-training-set.csv', \n",
    "                           usecols=['screen_name', 'name', 'description', 'hotel'])\n",
    "training_set = training_set.replace(np.nan, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "marked-afternoon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>hotel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aldemar_resorts</td>\n",
       "      <td>Aldemar Resorts</td>\n",
       "      <td>Guest satisfaction is our top priority! *Luxur...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AquaVistaHotels</td>\n",
       "      <td>Aqua Vista Hotels</td>\n",
       "      <td>A compilation of extraordinary hotels catering...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eurobank_Group</td>\n",
       "      <td>Eurobank</td>\n",
       "      <td>Καλωσήρθατε στην επίσημη σελίδα της Eurobank σ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>white_suites</td>\n",
       "      <td>White Suites Resort</td>\n",
       "      <td>White Suites Resort is a luxury beach hotel in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KarenMillen</td>\n",
       "      <td>Karen Millen</td>\n",
       "      <td>Timeless, elevated ready-to-wear style for women.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       screen_name                 name  \\\n",
       "0  aldemar_resorts      Aldemar Resorts   \n",
       "1  AquaVistaHotels    Aqua Vista Hotels   \n",
       "2   Eurobank_Group             Eurobank   \n",
       "3     white_suites  White Suites Resort   \n",
       "4      KarenMillen         Karen Millen   \n",
       "\n",
       "                                         description  hotel  \n",
       "0  Guest satisfaction is our top priority! *Luxur...      1  \n",
       "1  A compilation of extraordinary hotels catering...      1  \n",
       "2  Καλωσήρθατε στην επίσημη σελίδα της Eurobank σ...      0  \n",
       "3  White Suites Resort is a luxury beach hotel in...      1  \n",
       "4  Timeless, elevated ready-to-wear style for women.      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-recipe",
   "metadata": {},
   "source": [
    "# Case 1: name + description \n",
    "---\n",
    "In this case, we use a node's name and description  as a single feature to classify the node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-ocean",
   "metadata": {},
   "source": [
    "## Text Normalization\n",
    "We start by creating a new field:\n",
    "- textdata : name + description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "atlantic-exposure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>hotel</th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aldemar_resorts</td>\n",
       "      <td>1</td>\n",
       "      <td>Aldemar Resorts Guest satisfaction is our top ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AquaVistaHotels</td>\n",
       "      <td>1</td>\n",
       "      <td>Aqua Vista Hotels A compilation of extraordina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eurobank_Group</td>\n",
       "      <td>0</td>\n",
       "      <td>Eurobank Καλωσήρθατε στην επίσημη σελίδα της E...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       screen_name  hotel                                         textdata_1\n",
       "0  aldemar_resorts      1  Aldemar Resorts Guest satisfaction is our top ...\n",
       "1  AquaVistaHotels      1  Aqua Vista Hotels A compilation of extraordina...\n",
       "2   Eurobank_Group      0  Eurobank Καλωσήρθατε στην επίσημη σελίδα της E..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = training_set.copy()\n",
    "data['textdata_1'] = data['name'] + ' ' + data['description']\n",
    "data = data.drop(['name', 'description'], axis = 1)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-major",
   "metadata": {},
   "source": [
    "Next normalize our text by taking the following actions:\n",
    "\n",
    "- remove URLs\n",
    "- remove anything that isn't a unicode character (e.g emojis, punctuation)\n",
    "- remove numbers and _\n",
    "- fix whitespace\n",
    "- convert to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "metropolitan-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['textdata_1'] = clean_text(data['textdata_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-dividend",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "intended-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_tfidf = pd.DataFrame()\n",
    "\n",
    "lr_tfidf = pd.DataFrame()\n",
    "\n",
    "knn_tfidf = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-hepatitis",
   "metadata": {},
   "source": [
    "### Without NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sound-hurricane",
   "metadata": {},
   "outputs": [],
   "source": [
    "textdatas = ['textdata_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-policy",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "piano-restaurant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac30762b374a48b29f8c8cae888e6acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'svm__C': 1, 'svm__kernel': 'linear', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.8 0.8 0.8 ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             textdata_1\n",
       "Without NLP         0.9"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_svm(X, data['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_tfidf = svm_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "svm_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-supplement",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "earned-defeat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d657c04014d140e784b0bc7efeb85ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'lr__C': 10, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             textdata_1\n",
       "Without NLP       0.895"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_lr(X, data['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_tfidf = lr_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "lr_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-consent",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "prompt-consideration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a4c10a948d4b3f82f651dfdf45ed37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'knn__n_neighbors': 3, 'knn__weights': 'uniform', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.77 0.77 0.77 ...  nan  nan  nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             textdata_1\n",
       "Without NLP        0.89"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_knn(X, data['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_tfidf = knn_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "knn_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-comedy",
   "metadata": {},
   "source": [
    "### Stop Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "honest-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_el = spacy.load('el_core_news_md')\n",
    "nlp_en = spacy.load('en_core_web_sm')\n",
    "STOPWORDS = set(list(spacy.lang.en.STOP_WORDS) + list(spacy.lang.el.STOP_WORDS))\n",
    "\n",
    "def remove_stopwords(row):\n",
    "    row = [str(token) for token in nlp_el(row)]\n",
    "    return [w for w in row if w not in STOPWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "determined-resort",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: remove_stopwords(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: ' '.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-orleans",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fixed-dominant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8e2095ccbc43619eecd549eb61f430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'svm__C': 1, 'svm__kernel': 'linear', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.81 0.82 0.81 ...  nan  nan  nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1\n",
       "Without NLP            0.900\n",
       "Stopword Removal       0.915"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_svm(X, df['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_tfidf = svm_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "svm_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-beauty",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cooperative-research",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40cab7cb7b0943159f9ea2c56ca473c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'lr__C': 5, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 100, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1\n",
       "Without NLP            0.895\n",
       "Stopword Removal       0.905"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_lr(X, df['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_tfidf = lr_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "lr_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-butterfly",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "separated-probability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31c341111a749f98dfcde4e4841150e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'knn__n_neighbors': 4, 'knn__weights': 'uniform', 'vectorizer__max_df': 0.25, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.63 0.63 0.59 ...  nan  nan  nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1\n",
       "Without NLP             0.89\n",
       "Stopword Removal        0.89"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_knn(X, df['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_tfidf = knn_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "knn_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-version",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "imposed-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lemmatize(row):\n",
    "    return [str(token.lemma_) for token in nlp_el(row)]\n",
    "\n",
    "def tokenize_lemmatize_en(row):\n",
    "    return [str(token.lemma_) for token in nlp_en(row)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "everyday-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: tokenize_lemmatize(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: ' '.join(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: tokenize_lemmatize_en(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: ' '.join(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: remove_stopwords(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: ' '.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-hierarchy",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "proud-accuracy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1f58d6a47f410fb65ffcc4fdd1c4bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'svm__C': 1, 'svm__kernel': 'rbf', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.83 0.84 0.83 ...  nan  nan  nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1\n",
       "Without NLP            0.900\n",
       "Stopword Removal       0.915\n",
       "Lemmatization          0.920"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_svm(X, df['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_tfidf = svm_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "\n",
    "svm_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-building",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "israeli-accommodation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ab3334f8cd425a8ad3ff6db76d3cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'lr__C': 0.5, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 100, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1\n",
       "Without NLP            0.895\n",
       "Stopword Removal       0.905\n",
       "Lemmatization          0.905"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_lr(X, df['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_tfidf = lr_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "\n",
    "lr_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-planner",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "freelance-voice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83dc4f0076a8422fb53d32638a997bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'knn__n_neighbors': 4, 'knn__weights': 'uniform', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.7   0.69  0.695 ...   nan   nan   nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_1\n",
       "Without NLP            0.890\n",
       "Stopword Removal       0.890\n",
       "Lemmatization          0.885"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_knn(X, df['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_tfidf = knn_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "\n",
    "knn_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-fundamental",
   "metadata": {},
   "source": [
    "### Remove named entities (Country Names and Geographic Locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "interior-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_named_entities_en(row):\n",
    "    return [str(token) for token in nlp_en(row) if token.ent_type_ not in set(['NORP', 'GPE'])]\n",
    "\n",
    "def remove_named_entities_el(row):\n",
    "    return [str(token) for token in nlp_el(row) if token.ent_type_ not in set(['NORP', 'GPE'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "revised-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: remove_named_entities_en(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: ' '.join(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: remove_named_entities_el(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: ' '.join(row))\n",
    "\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: tokenize_lemmatize(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: ' '.join(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: tokenize_lemmatize_en(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: ' '.join(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: remove_stopwords(row))\n",
    "df['textdata_1'] = df['textdata_1'].apply(lambda row: ' '.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-convenience",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "tracked-terminal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "228d7ef6dee74261af27a181ea180547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'svm__C': 1, 'svm__kernel': 'rbf', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.835 0.84  0.83  ...   nan   nan   nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Named Entities Removal</th>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Named Entities Removal</th>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        textdata_1\n",
       "Without NLP                  0.900\n",
       "Stopword Removal             0.915\n",
       "Lemmatization                0.920\n",
       "Named Entities Removal       0.920\n",
       "Named Entities Removal       0.920"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df_2[textdata]\n",
    "    results[textdata] = classification_svm(X, df_2['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_tfidf = svm_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Named Entities Removal']).T)\n",
    "\n",
    "svm_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-obligation",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "tough-assembly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e777f21942d43ec8a3b75b8cac9c5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'lr__C': 0.5, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Named Entities Removal</th>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Named Entities Removal</th>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        textdata_1\n",
       "Without NLP                  0.895\n",
       "Stopword Removal             0.905\n",
       "Lemmatization                0.905\n",
       "Named Entities Removal       0.900\n",
       "Named Entities Removal       0.900"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df_2[textdata]\n",
    "    results[textdata] = classification_lr(X, df_2['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_tfidf = lr_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Named Entities Removal']).T)\n",
    "\n",
    "lr_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-migration",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "advanced-burns",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b76a7c4ab2417abf9b584b93f1ecad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_1:\n",
      "{'knn__n_neighbors': 4, 'knn__weights': 'uniform', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.695 0.69  0.695 ...   nan   nan   nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Named Entities Removal</th>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Named Entities Removal</th>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        textdata_1\n",
       "Without NLP                  0.890\n",
       "Stopword Removal             0.890\n",
       "Lemmatization                0.885\n",
       "Named Entities Removal       0.890\n",
       "Named Entities Removal       0.890"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df_2[textdata]\n",
    "    results[textdata] = classification_knn(X, df_2['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_tfidf = knn_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Named Entities Removal']).T)\n",
    "\n",
    "knn_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-rendering",
   "metadata": {},
   "source": [
    "## Export Model\n",
    "\n",
    "\n",
    "The best model we found is: SVM-TF-IDF\n",
    "- vectorizer__max_df: 0.5\n",
    "- vectorizer__max_features: 1000\n",
    "- vectorizer__min_df: 1\n",
    "- svm__C: 1\n",
    "- svm_kernel: rbf<br>\n",
    "\n",
    "with the following NLP steps:\n",
    "- Lemmatization\n",
    "- Stop Word Removal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "foster-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_data_hotel_nd(df):\n",
    "    df['textdata'] = clean_text(df['name'] + ' ' + df['description'])\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: tokenize_lemmatize(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: ' '.join(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: tokenize_lemmatize_en(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: ' '.join(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: remove_stopwords(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: ' '.join(row))\n",
    "    \n",
    "    return df.textdata\n",
    "\n",
    "\n",
    "get_text = FunctionTransformer(get_text_data_hotel_nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "threaded-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('selector', get_text),\n",
    "    ('tfidf', TfidfVectorizer(max_df=0.5, max_features=1000, min_df=1)),\n",
    "    ('svm', svm.SVC(kernel='rbf', C=1, probability=True))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "stuffed-multimedia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('selector',\n",
       "                 FunctionTransformer(func=<function get_text_data_hotel_nd at 0x7fa6b5ebad30>)),\n",
       "                ('tfidf', TfidfVectorizer(max_df=0.5, max_features=1000)),\n",
       "                ('svm', SVC(C=1, probability=True))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = training_set\n",
    "y = training_set['hotel']\n",
    "pipeline.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "therapeutic-basketball",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classifier_hotel_nd.sav']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'classifier_hotel_nd.sav'\n",
    "joblib.dump(pipeline, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-simon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
