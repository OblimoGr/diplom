{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "peripheral-ordinary",
   "metadata": {},
   "source": [
    "# Classification Experiment: Tweets\n",
    "---\n",
    "This Notebook, includes a series of experiments, on using a node's tweets for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-february",
   "metadata": {},
   "source": [
    "Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abandoned-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import json\n",
    "import tweepy\n",
    "import time\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-vancouver",
   "metadata": {},
   "source": [
    "Twitter API Authentication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "continent-format",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_credentials = []\n",
    "with open('../../../../twitter_credentials.json', 'r') as f:\n",
    "    twitter_credentials = json.load(f)\n",
    "\n",
    "auth = tweepy.OAuthHandler(twitter_credentials['consumer_key'], twitter_credentials['consumer_secret'])\n",
    "auth.set_access_token(twitter_credentials['access_token_key'],twitter_credentials['access_token_secret'])\n",
    "API = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, timeout=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-arrival",
   "metadata": {},
   "source": [
    "Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceramic-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function For Text Normalization\n",
    "def clean_text(data):\n",
    "    urls = r'http\\S+'\n",
    "    non_unicode_char = r'\\W'\n",
    "    numbers = r'[0-9_]'\n",
    "    fix_whitespace = r'\\s+'\n",
    "    single_whitespace = ' '\n",
    "    \n",
    "    data = (data.replace([urls], single_whitespace, regex=True)\n",
    "                    .replace([non_unicode_char, numbers], single_whitespace, regex=True)\n",
    "                    .replace(fix_whitespace, single_whitespace, regex=True))\n",
    "    data = data.apply(lambda s: s.lower() if type(s) == str else s)\n",
    "    return data\n",
    "\n",
    "nlp_el = spacy.load('el_core_news_md')\n",
    "nlp_en = spacy.load('en_core_web_sm')\n",
    "STOPWORDS = set(list(spacy.lang.en.STOP_WORDS) + list(spacy.lang.el.STOP_WORDS))\n",
    "\n",
    "def remove_stopwords(row):\n",
    "    row = [str(token) for token in nlp_el(row)]\n",
    "    return [w for w in row if w not in STOPWORDS]\n",
    "\n",
    "def tokenize_lemmatize(row):\n",
    "    return [str(token.lemma_) for token in nlp_el(row)]\n",
    "\n",
    "def tokenize_lemmatize_en(row):\n",
    "    return [str(token.lemma_) for token in nlp_en(row)]\n",
    "\n",
    "# Function For Support Vector Machine\n",
    "def classification_svm(X, y, vect):\n",
    "    if vect == 'TF-IDF':\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer()),\n",
    "            ('svm', svm.SVC())\n",
    "        ]\n",
    "        )\n",
    "    elif vect == 'BoW':\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', CountVectorizer()),\n",
    "            ('svm', svm.SVC())\n",
    "        ]\n",
    "        )\n",
    "\n",
    "    parameters = {'vectorizer__max_df': [0.25, 0.5, 0.75, 1],\n",
    "                  'vectorizer__min_df': [1, 5, 10, 25],\n",
    "                  'vectorizer__max_features': [10, 100, 1000, 2000, None],\n",
    "                  'svm__C' : [0.1,0.5,1,5,10],\n",
    "                  'svm__kernel':['linear', 'poly', 'rbf', 'sigmoid']\n",
    "                  }\n",
    "    \n",
    "    grid = GridSearchCV(pipeline, parameters, n_jobs = 4)\n",
    "    grid.fit(X, y)\n",
    "    \n",
    "    print(grid.best_params_)\n",
    "    return grid.best_score_\n",
    "\n",
    "# Function For Logistic Regression\n",
    "def classification_lr(X, y, vect):\n",
    "    if vect == 'TF-IDF':\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer()),\n",
    "            ('lr', LogisticRegression(max_iter=1000))\n",
    "        ]\n",
    "        )\n",
    "    elif vect == 'BoW':\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', CountVectorizer()),\n",
    "            ('lr', LogisticRegression(max_iter=1000))\n",
    "        ]\n",
    "        )\n",
    "\n",
    "    parameters = {'vectorizer__max_df': [0.25, 0.5, 0.75, 1],\n",
    "                  'vectorizer__min_df': [1, 5, 10, 25],\n",
    "                  'vectorizer__max_features': [10, 100, 1000, 2000, None],\n",
    "                  'lr__penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                  'lr__C': [0.1, 0.5, 1, 5, 10]\n",
    "                  }\n",
    "    \n",
    "    grid = GridSearchCV(pipeline, parameters, n_jobs = 4)\n",
    "    grid.fit(X, y)\n",
    "    \n",
    "    print(grid.best_params_)\n",
    "    return grid.best_score_\n",
    "\n",
    "# Function For kNN\n",
    "def classification_knn(X, y, vect):\n",
    "    if vect == 'TF-IDF':\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer()),\n",
    "            ('knn', KNeighborsClassifier())\n",
    "        ]\n",
    "        )\n",
    "    elif vect == 'BoW':\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', CountVectorizer()),\n",
    "            ('knn', KNeighborsClassifier())\n",
    "        ]\n",
    "        )\n",
    "\n",
    "    parameters = {'vectorizer__max_df': [0.25, 0.5, 0.75, 1],\n",
    "                  'vectorizer__min_df': [1, 5, 10, 25],\n",
    "                  'vectorizer__max_features': [10, 100, 1000, 2000, None],\n",
    "                  'knn__n_neighbors': [1,2,3,4,5,6,7,8,9,10],\n",
    "                  'knn__weights': ['uniform', 'distance']\n",
    "                  }\n",
    "    \n",
    "    grid = GridSearchCV(pipeline, parameters, n_jobs = 4)\n",
    "    grid.fit(X, y)\n",
    "    \n",
    "    print(grid.best_params_)\n",
    "    return grid.best_score_\n",
    "\n",
    "\n",
    "def get_text_data_nd(df):\n",
    "    df['textdata'] = clean_text(df['name'] + ' ' + df['description'])\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: tokenize_lemmatize(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: ' '.join(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: remove_stopwords(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: ' '.join(row))\n",
    "    \n",
    "    return df.textdata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-practitioner",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "shaped-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Training Set\n",
    "training_set = pd.read_csv('../../../../datasets/Hotels/classification/hotels-training-set.csv',\n",
    "                          usecols=['screen_name', 'name', 'description', 'recent_100_statuses', 'hotel'])\n",
    "training_set = training_set.replace(np.nan, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "retained-pension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>recent_100_statuses</th>\n",
       "      <th>hotel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aldemar_resorts</td>\n",
       "      <td>Aldemar Resorts</td>\n",
       "      <td>Guest satisfaction is our top priority! *Luxur...</td>\n",
       "      <td>Summer vacation is meant to make you feel ⛱ r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AquaVistaHotels</td>\n",
       "      <td>Aqua Vista Hotels</td>\n",
       "      <td>A compilation of extraordinary hotels catering...</td>\n",
       "      <td>Thank you Greek Travel Pages for highlighting...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eurobank_Group</td>\n",
       "      <td>Eurobank</td>\n",
       "      <td>Καλωσήρθατε στην επίσημη σελίδα της Eurobank σ...</td>\n",
       "      <td>Η Eurobank ενημερώνει ότι τα συστήματά της, κ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>white_suites</td>\n",
       "      <td>White Suites Resort</td>\n",
       "      <td>White Suites Resort is a luxury beach hotel in...</td>\n",
       "      <td>Sea side holidays in Afytos, Halikidiki White...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KarenMillen</td>\n",
       "      <td>Karen Millen</td>\n",
       "      <td>Timeless, elevated ready-to-wear style for women.</td>\n",
       "      <td>The future's bright.\\nhttps://t.co/XLpskBYi4u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       screen_name                 name  \\\n",
       "0  aldemar_resorts      Aldemar Resorts   \n",
       "1  AquaVistaHotels    Aqua Vista Hotels   \n",
       "2   Eurobank_Group             Eurobank   \n",
       "3     white_suites  White Suites Resort   \n",
       "4      KarenMillen         Karen Millen   \n",
       "\n",
       "                                         description  \\\n",
       "0  Guest satisfaction is our top priority! *Luxur...   \n",
       "1  A compilation of extraordinary hotels catering...   \n",
       "2  Καλωσήρθατε στην επίσημη σελίδα της Eurobank σ...   \n",
       "3  White Suites Resort is a luxury beach hotel in...   \n",
       "4  Timeless, elevated ready-to-wear style for women.   \n",
       "\n",
       "                                 recent_100_statuses  hotel  \n",
       "0   Summer vacation is meant to make you feel ⛱ r...      1  \n",
       "1   Thank you Greek Travel Pages for highlighting...      1  \n",
       "2   Η Eurobank ενημερώνει ότι τα συστήματά της, κ...      0  \n",
       "3   Sea side holidays in Afytos, Halikidiki White...      1  \n",
       "4   The future's bright.\\nhttps://t.co/XLpskBYi4u...      0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-skiing",
   "metadata": {},
   "source": [
    "# Case 1: name + description + tweets\n",
    "---\n",
    "In this case, we use a node's name, description and tweets as a single feature to classify the node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-lewis",
   "metadata": {},
   "source": [
    "## Text Normalization\n",
    "We start by creating 3 new fields:\n",
    "- textdata_1 : name + description + recent_tweet\n",
    "- textdata_2 : name + description + recent_10_tweets\n",
    "- textdata_3 : name + description + recent_100_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "preliminary-canadian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>hotel</th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aldemar_resorts</td>\n",
       "      <td>1</td>\n",
       "      <td>Aldemar Resorts Guest satisfaction is our top ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AquaVistaHotels</td>\n",
       "      <td>1</td>\n",
       "      <td>Aqua Vista Hotels A compilation of extraordina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eurobank_Group</td>\n",
       "      <td>0</td>\n",
       "      <td>Eurobank Καλωσήρθατε στην επίσημη σελίδα της E...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       screen_name  hotel                                         textdata_3\n",
       "0  aldemar_resorts      1  Aldemar Resorts Guest satisfaction is our top ...\n",
       "1  AquaVistaHotels      1  Aqua Vista Hotels A compilation of extraordina...\n",
       "2   Eurobank_Group      0  Eurobank Καλωσήρθατε στην επίσημη σελίδα της E..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = training_set.copy()\n",
    "data['textdata_3'] = data['name'] + ' ' + data['description'] + ' ' + data['recent_100_statuses']\n",
    "data = data.drop(['name', 'description', 'recent_100_statuses'], axis = 1)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-variety",
   "metadata": {},
   "source": [
    "Next normalize our text by taking the following actions:\n",
    "\n",
    "- remove URLss\n",
    "- remove anything that isn't a unicode character (e.g emojis, punctuation)\n",
    "- remove numbers and _\n",
    "- fix whitespace\n",
    "- convert to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "working-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['textdata_3'] = clean_text(data['textdata_3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-combination",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "accepted-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_tfidf = pd.DataFrame()\n",
    "lr_tfidf = pd.DataFrame()\n",
    "knn_tfidf = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-final",
   "metadata": {},
   "source": [
    "### Without NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "registered-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "textdatas = ['textdata_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-clothing",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "protective-running",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96baa502ce274ab4a8730e2bb16461a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.79 0.79 0.79 ...  nan  nan  nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 1, 'svm__kernel': 'rbf', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 10}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             textdata_3\n",
       "Without NLP       0.905"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_svm(X, data['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_tfidf = svm_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "svm_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-light",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "beneficial-services",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17daee4d512f4baba88b3fb78a4195fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 5, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': None, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             textdata_3\n",
       "Without NLP       0.875"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_lr(X, data['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_tfidf = lr_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "lr_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-cabinet",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "individual-thumbnail",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "627d51e365764e2d96438785eb960119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.785 0.785 0.785 ...   nan   nan   nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 8, 'knn__weights': 'distance', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 100, 'vectorizer__min_df': 5}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             textdata_3\n",
       "Without NLP       0.865"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_knn(X, data['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_tfidf = knn_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "knn_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-professor",
   "metadata": {},
   "source": [
    "### Stop Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "environmental-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_el = spacy.load('el_core_news_md')\n",
    "nlp_en = spacy.load('en_core_web_sm')\n",
    "STOPWORDS = set(list(spacy.lang.en.STOP_WORDS) + list(spacy.lang.el.STOP_WORDS))\n",
    "\n",
    "def remove_stopwords(row):\n",
    "    row = [str(token) for token in nlp_el(row)]\n",
    "    return [w for w in row if w not in STOPWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "tender-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: remove_stopwords(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: ' '.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-maintenance",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "alert-antique",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f87238716941ebbc9cea22b1689803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.775 0.775 0.775 ...   nan   nan   nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 1, 'svm__kernel': 'rbf', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_3\n",
       "Without NLP            0.905\n",
       "Stopword Removal       0.910"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_svm(X, df['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_tfidf = svm_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "svm_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-calcium",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "decent-accommodation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f401ed510c984721972e12011485a0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 0.1, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 25}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_3\n",
       "Without NLP            0.875\n",
       "Stopword Removal       0.900"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_lr(X, df['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_tfidf = lr_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "lr_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-democrat",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dominican-prize",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78966ca10dbc40e9a4ad9236ec2829bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.73 0.73 0.73 ...  nan  nan  nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 8, 'knn__weights': 'uniform', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': None, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_3\n",
       "Without NLP            0.865\n",
       "Stopword Removal       0.875"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_knn(X, df['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_tfidf = knn_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "knn_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-laugh",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "hungry-baghdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lemmatize(row):\n",
    "    return [str(token.lemma_) for token in nlp_el(row)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "auburn-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: tokenize_lemmatize(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: ' '.join(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: tokenize_lemmatize_en(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: ' '.join(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: remove_stopwords(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: ' '.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-education",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "headed-webster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4879f8f0e448fca3991fb2262304cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.785 0.785 0.785 ...   nan   nan   nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 1, 'svm__kernel': 'rbf', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': 100, 'vectorizer__min_df': 10}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_3\n",
       "Without NLP            0.905\n",
       "Stopword Removal       0.910\n",
       "Lemmatization          0.920"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_svm(X, df['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_tfidf = svm_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "\n",
    "svm_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-maine",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "immune-duration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b42bd5b7e042f495f1702fcb11298e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 1, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 25}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_3\n",
       "Without NLP            0.875\n",
       "Stopword Removal       0.900\n",
       "Lemmatization          0.910"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_lr(X, df['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_tfidf = lr_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "\n",
    "lr_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-shareware",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "activated-ceiling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46712d58e544df09175e7139d9a7314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_3:\n",
      "{'knn__n_neighbors': 8, 'knn__weights': 'uniform', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': None, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.72 0.72 0.72 ...  nan  nan  nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  textdata_3\n",
       "Without NLP            0.865\n",
       "Stopword Removal       0.875\n",
       "Lemmatization          0.870"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_knn(X, df['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_tfidf = knn_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "\n",
    "knn_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-acceptance",
   "metadata": {},
   "source": [
    "### Named Entity Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "czech-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_named_entities_en(row):\n",
    "    return [str(token) for token in nlp_en(row) if token.ent_type_ not in set(['NORP', 'GPE'])]\n",
    "\n",
    "def remove_named_entities_el(row):\n",
    "    return [str(token) for token in nlp_el(row) if token.ent_type_ not in set(['NORP', 'GPE'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "expected-consistency",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: remove_named_entities_en(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: ' '.join(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: remove_named_entities_el(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: ' '.join(row))\n",
    "\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: tokenize_lemmatize(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: ' '.join(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: tokenize_lemmatize_en(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: ' '.join(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: remove_stopwords(row))\n",
    "df['textdata_3'] = df['textdata_3'].apply(lambda row: ' '.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-orleans",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "approved-twelve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2063249e982c44359ffe3cdd9ffaae4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.785 0.785 0.785 ...   nan   nan   nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 1, 'svm__kernel': 'rbf', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': 100, 'vectorizer__min_df': 10}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Named Entities Removal</th>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        textdata_3\n",
       "Without NLP                  0.905\n",
       "Stopword Removal             0.910\n",
       "Lemmatization                0.920\n",
       "Named Entities Removal       0.920"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_svm(X, df['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_tfidf = svm_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Named Entities Removal']).T)\n",
    "\n",
    "svm_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-packet",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "certain-constitution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7af749a4004762be73a2aab0e3360a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 1, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 25}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Named Entities Removal</th>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        textdata_3\n",
       "Without NLP                  0.875\n",
       "Stopword Removal             0.900\n",
       "Lemmatization                0.910\n",
       "Named Entities Removal       0.910"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_lr(X, df['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_tfidf = lr_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Named Entities Removal']).T)\n",
    "\n",
    "lr_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-sponsorship",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "illegal-model",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1611738cb75b4afab85d7468532901c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for textdata_3:\n",
      "{'knn__n_neighbors': 8, 'knn__weights': 'uniform', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': None, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.72 0.72 0.72 ...  nan  nan  nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textdata_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Named Entities Removal</th>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        textdata_3\n",
       "Without NLP                  0.865\n",
       "Stopword Removal             0.875\n",
       "Lemmatization                0.870\n",
       "Named Entities Removal       0.870"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_knn(X, df['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_tfidf = knn_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Named Entities Removal']).T)\n",
    "\n",
    "knn_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-transportation",
   "metadata": {},
   "source": [
    "### Export Model\n",
    "- TF-IDF outperformed BoW with in every case.\n",
    "- Highest Accuracy was achieved using recent 100 tweets\n",
    "- Support Vector Machine and Logistic Regression have a better performance.\n",
    "- Logistic Regression Reached the highest achieved accuracy with less NLP steps than Support Vector Machines\n",
    "\n",
    "The best models we found are: Support Vector Machines - TF-IDF.\n",
    "\n",
    "- vectorizer__max_df: 0.75\n",
    "- vectorizer__max_features: 100\n",
    "- vectorizer__min_df: 10\n",
    "- svm__C: 1\n",
    "- svm__kernel: rbf<br>\n",
    "\n",
    "with the following NLP steps:\n",
    "- Lemmatization\n",
    "- Stop Word Removal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "hindu-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_data_hotel_ndt(df):\n",
    "    df['textdata'] = clean_text(df['name'] + ' ' + df['description'] + ' ' + df['recent_100_statuses'])\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: tokenize_lemmatize(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: ' '.join(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: remove_stopwords(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: ' '.join(row))\n",
    "    return df.textdata\n",
    "\n",
    "\n",
    "get_text_ndt = FunctionTransformer(get_text_data_hotel_ndt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "signal-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('selector_ndt', get_text_ndt),\n",
    "    ('tfidf', TfidfVectorizer(max_df=0.75, max_features=100, min_df=10)),\n",
    "    ('svm', svm.SVC(kernel='rbf', C=1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "nervous-patrick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('selector_ndt',\n",
       "                 FunctionTransformer(func=<function get_text_data_hotel_ndt at 0x7fbb1cb24040>)),\n",
       "                ('tfidf',\n",
       "                 TfidfVectorizer(max_df=0.75, max_features=100, min_df=10)),\n",
       "                ('svm', SVC(C=1))])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = training_set\n",
    "y = training_set.hotel\n",
    "pipeline.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "mature-wisconsin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../classifiers/classifier_hotel_ndt.sav']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '../classifiers/classifier_hotel_ndt.sav'\n",
    "joblib.dump(pipeline, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-november",
   "metadata": {},
   "source": [
    "# Case 2: Tweets Only\n",
    "---\n",
    "In this case we fetch 100 tweets if possible for each node, and try to classify them using only their tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-london",
   "metadata": {},
   "source": [
    "## Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "material-unknown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>recent_100_statuses</th>\n",
       "      <th>hotel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aldemar_resorts</td>\n",
       "      <td>Aldemar Resorts</td>\n",
       "      <td>Guest satisfaction is our top priority! *Luxur...</td>\n",
       "      <td>Summer vacation is meant to make you feel ⛱ r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AquaVistaHotels</td>\n",
       "      <td>Aqua Vista Hotels</td>\n",
       "      <td>A compilation of extraordinary hotels catering...</td>\n",
       "      <td>Thank you Greek Travel Pages for highlighting...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eurobank_Group</td>\n",
       "      <td>Eurobank</td>\n",
       "      <td>Καλωσήρθατε στην επίσημη σελίδα της Eurobank σ...</td>\n",
       "      <td>Η Eurobank ενημερώνει ότι τα συστήματά της, κ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       screen_name               name  \\\n",
       "0  aldemar_resorts    Aldemar Resorts   \n",
       "1  AquaVistaHotels  Aqua Vista Hotels   \n",
       "2   Eurobank_Group           Eurobank   \n",
       "\n",
       "                                         description  \\\n",
       "0  Guest satisfaction is our top priority! *Luxur...   \n",
       "1  A compilation of extraordinary hotels catering...   \n",
       "2  Καλωσήρθατε στην επίσημη σελίδα της Eurobank σ...   \n",
       "\n",
       "                                 recent_100_statuses  hotel  \n",
       "0   Summer vacation is meant to make you feel ⛱ r...      1  \n",
       "1   Thank you Greek Travel Pages for highlighting...      1  \n",
       "2   Η Eurobank ενημερώνει ότι τα συστήματά της, κ...      0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = training_set.copy()\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-investigator",
   "metadata": {},
   "source": [
    "We normalize our text by taking the following actions:\n",
    "\n",
    "- remove URLs\n",
    "- remove anything that isn't a unicode character (e.g emojis, punctuation)\n",
    "- remove numbers and _\n",
    "- fix whitespace\n",
    "- convert to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "established-plumbing",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['recent_100_statuses'] = clean_text(data['recent_100_statuses'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-stopping",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "underlying-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "textdatas = ['recent_100_statuses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "lightweight-register",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_tfidf = pd.DataFrame()\n",
    "lr_tfidf = pd.DataFrame()\n",
    "knn_tfidf = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-casino",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "persistent-working",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43abcf8804604516936207ce6240bec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for recent_100_statuses:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.755 0.755 0.755 ...   nan   nan   nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 1, 'svm__kernel': 'rbf', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 10}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recent_100_statuses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             recent_100_statuses\n",
       "Without NLP                0.895"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_svm(X, data['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_tfidf = svm_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "svm_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-batch",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "alone-satin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17079f1939e6418eb7cdb0b817ed2bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for recent_100_statuses:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 10, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 100, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recent_100_statuses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             recent_100_statuses\n",
       "Without NLP                 0.85"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_lr(X, data['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_tfidf = lr_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "lr_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-niagara",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fifty-railway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d2e2f7618446daa0d0b4950f2846f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for recent_100_statuses:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.745 0.745 0.745 ...   nan   nan   nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 4, 'knn__weights': 'uniform', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': 100, 'vectorizer__min_df': 25}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recent_100_statuses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             recent_100_statuses\n",
       "Without NLP                0.825"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = data[textdata]\n",
    "    results[textdata] = classification_knn(X, data['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_tfidf = knn_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Without NLP']).T)\n",
    "\n",
    "knn_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-routine",
   "metadata": {},
   "source": [
    "### Stop Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "related-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_el = spacy.load('el_core_news_md')\n",
    "nlp_en = spacy.load('en_core_web_sm')\n",
    "STOPWORDS = set(list(spacy.lang.en.STOP_WORDS) + list(spacy.lang.el.STOP_WORDS))\n",
    "\n",
    "def remove_stopwords(row):\n",
    "    row = [str(token) for token in nlp_el(row)]\n",
    "    return [w for w in row if w not in STOPWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "chronic-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "\n",
    "df['recent_100_statuses'] = df['recent_100_statuses'].apply(lambda row: remove_stopwords(row))\n",
    "df['recent_100_statuses'] = df['recent_100_statuses'].apply(lambda row: ' '.join(row))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-recipe",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "radical-performer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c866322a41b4bed8c0eb38079d65d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for recent_100_statuses:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.765 0.765 0.765 ...   nan   nan   nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 5, 'svm__kernel': 'rbf', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recent_100_statuses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  recent_100_statuses\n",
       "Without NLP                     0.895\n",
       "Stopword Removal                0.895"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_svm(X, df['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_tfidf = svm_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "svm_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-mailman",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "loaded-burton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcb39a13c3b47918ce93e9ff14b69bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for recent_100_statuses:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 10, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 5}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recent_100_statuses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  recent_100_statuses\n",
       "Without NLP                      0.85\n",
       "Stopword Removal                 0.88"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_lr(X, df['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_tfidf = lr_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "lr_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-delay",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "subjective-candy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c455b9f5f2c44c5dbf6d815171898590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for recent_100_statuses:\n",
      "{'knn__n_neighbors': 4, 'knn__weights': 'distance', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': 10, 'vectorizer__min_df': 1}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.72 0.72 0.72 ...  nan  nan  nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recent_100_statuses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  recent_100_statuses\n",
       "Without NLP                     0.825\n",
       "Stopword Removal                0.815"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_knn(X, df['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_tfidf = knn_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Stopword Removal']).T)\n",
    "\n",
    "knn_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-whole",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cutting-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lemmatize(row):\n",
    "    return [str(token.lemma_) for token in nlp_el(row)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "political-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "\n",
    "df['recent_100_statuses'] = df['recent_100_statuses'].apply(lambda row: tokenize_lemmatize(row))\n",
    "df['recent_100_statuses'] = df['recent_100_statuses'].apply(lambda row: ' '.join(row))\n",
    "df['recent_100_statuses'] = df['recent_100_statuses'].apply(lambda row: tokenize_lemmatize_en(row))\n",
    "df['recent_100_statuses'] = df['recent_100_statuses'].apply(lambda row: ' '.join(row))\n",
    "df['recent_100_statuses'] = df['recent_100_statuses'].apply(lambda row: remove_stopwords(row))\n",
    "df['recent_100_statuses'] = df['recent_100_statuses'].apply(lambda row: ' '.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-primary",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "editorial-grenada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0baae7c5731f482d8fb27ad62ce1ecf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for recent_100_statuses:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.75 0.75 0.75 ...  nan  nan  nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 1, 'svm__kernel': 'rbf', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': 2000, 'vectorizer__min_df': 5}\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recent_100_statuses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  recent_100_statuses\n",
       "Without NLP                     0.895\n",
       "Stopword Removal                0.895\n",
       "Lemmatization                   0.905"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_svm(X, df['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "svm_tfidf = svm_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "\n",
    "svm_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-rebecca",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "happy-portugal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8b63ab572846c5ab413f619f00c6ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for recent_100_statuses:\n",
      "{'lr__C': 10, 'lr__penalty': 'l2', 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 1000, 'vectorizer__min_df': 10}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recent_100_statuses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  recent_100_statuses\n",
       "Without NLP                      0.85\n",
       "Stopword Removal                 0.88\n",
       "Lemmatization                    0.88"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_lr(X, df['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "lr_tfidf = lr_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "\n",
    "lr_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-superior",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "accessory-tradition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac4e4a3669ac448c85416ea119d4d557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for recent_100_statuses:\n",
      "{'knn__n_neighbors': 9, 'knn__weights': 'distance', 'vectorizer__max_df': 0.75, 'vectorizer__max_features': 10, 'vectorizer__min_df': 25}\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.705 0.705 0.705 ...   nan   nan   nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recent_100_statuses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without NLP</th>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopword Removal</th>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatization</th>\n",
       "      <td>0.835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  recent_100_statuses\n",
       "Without NLP                     0.825\n",
       "Stopword Removal                0.815\n",
       "Lemmatization                   0.835"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "results = {}\n",
    "for textdata in tqdm(textdatas):\n",
    "    print(f'Best params for {textdata}:')\n",
    "    X = df[textdata]\n",
    "    results[textdata] = classification_knn(X, df['hotel'], 'TF-IDF').round(4)\n",
    "    print(\"============================\")\n",
    "    \n",
    "knn_tfidf = knn_tfidf.append(\n",
    "    pd.DataFrame.from_dict(results, orient='index', columns=['Lemmatization']).T)\n",
    "\n",
    "knn_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-hampton",
   "metadata": {},
   "source": [
    "### Export Model\n",
    "- TF-IDF outperformed BoW with in every case except with Logistic Regression, where they had similar performances\n",
    "- Logistic Regression had the best performance, and kNN the worst\n",
    "\n",
    "The best model we found is: SVM-TF-IDF\n",
    "- vectorizer__max_df: 0.75\n",
    "- vectorizer__max_features: 2000\n",
    "- vectorizer__min_df: 5\n",
    "- svm__C: 1\n",
    "- svm__kernel: rbf<br>\n",
    "\n",
    "with the following NLP steps:\n",
    "- Stop Word Removal\n",
    "- Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "adaptive-tobago",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_data_hotel_t(df):\n",
    "    df['textdata'] = clean_text(df['recent_100_statuses'])\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: tokenize_lemmatize(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: ' '.join(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: tokenize_lemmatize_en(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: ' '.join(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: remove_stopwords(row))\n",
    "    df['textdata'] = df['textdata'].apply(lambda row: ' '.join(row))\n",
    "    \n",
    "    return df.textdata\n",
    "\n",
    "\n",
    "get_text_t = FunctionTransformer(get_text_data_hotel_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "better-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('selector_t', get_text_t),\n",
    "    ('tfidf', TfidfVectorizer(max_df=0.75, max_features=None, min_df=5)),\n",
    "    ('svm', svm.SVC(kernel='rbf', C=1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "acknowledged-specification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('selector_t',\n",
       "                 FunctionTransformer(func=<function get_text_data_hotel_t at 0x7fbb3dba0670>)),\n",
       "                ('tfidf', TfidfVectorizer(max_df=0.75, min_df=5)),\n",
       "                ('svm', SVC(C=1))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = training_set\n",
    "y = training_set.hotel\n",
    "pipeline.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aboriginal-cocktail",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../classifiers/classifier_hotel_t.sav']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '../classifiers/classifier_hotel_t.sav'\n",
    "joblib.dump(pipeline, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-necklace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
